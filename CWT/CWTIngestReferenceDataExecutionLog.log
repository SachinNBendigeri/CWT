2019-10-02 18:51:21 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-10-02 18:51:21 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-02 18:51:22 INFO  SparkContext:54 - Submitted application: VehicleProcessing
2019-10-02 18:51:22 INFO  SecurityManager:54 - Changing view acls to: user
2019-10-02 18:51:22 INFO  SecurityManager:54 - Changing modify acls to: user
2019-10-02 18:51:22 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-10-02 18:51:22 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-10-02 18:51:22 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(user); groups with view permissions: Set(); users  with modify permissions: Set(user); groups with modify permissions: Set()
2019-10-02 18:51:23 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 62434.
2019-10-02 18:51:23 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-10-02 18:51:23 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-10-02 18:51:23 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-10-02 18:51:23 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-10-02 18:51:23 INFO  DiskBlockManager:54 - Created local directory at C:\Users\user\AppData\Local\Temp\blockmgr-86fa4683-1d8d-4e34-8f9d-9d1423579a48
2019-10-02 18:51:23 INFO  MemoryStore:54 - MemoryStore started with capacity 1965.3 MB
2019-10-02 18:51:23 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-10-02 18:51:23 INFO  log:192 - Logging initialized @3320ms
2019-10-02 18:51:23 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-10-02 18:51:23 INFO  Server:414 - Started @3457ms
2019-10-02 18:51:23 INFO  AbstractConnector:278 - Started ServerConnector@12c7a01b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-02 18:51:23 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-10-02 18:51:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67304a40{/jobs,null,AVAILABLE,@Spark}
2019-10-02 18:51:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d64e326{/jobs/json,null,AVAILABLE,@Spark}
2019-10-02 18:51:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@13f95696{/jobs/job,null,AVAILABLE,@Spark}
2019-10-02 18:51:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@68be8808{/jobs/job/json,null,AVAILABLE,@Spark}
2019-10-02 18:51:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32193bea{/stages,null,AVAILABLE,@Spark}
2019-10-02 18:51:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b8d96d9{/stages/json,null,AVAILABLE,@Spark}
2019-10-02 18:51:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69653e16{/stages/stage,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@906d29b{/stages/stage/json,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49d3c823{/stages/pool,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@436bc36{/stages/pool/json,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5fe1ce85{/storage,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@604c5de8{/storage/json,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@37091312{/storage/rdd,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66fdec9{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@57abad67{/environment,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@550a1967{/environment/json,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a640157{/executors,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52851b44{/executors/json,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@584f54e6{/executors/threadDump,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5d8bafa9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@576f63f6{/static,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@366ac49b{/,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ad59d92{/api,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44b3606b{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1477089c{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://user-PC:4040
2019-10-02 18:51:24 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-10-02 18:51:24 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62456.
2019-10-02 18:51:24 INFO  NettyBlockTransferService:54 - Server created on user-PC:62456
2019-10-02 18:51:24 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-10-02 18:51:24 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, user-PC, 62456, None)
2019-10-02 18:51:24 INFO  BlockManagerMasterEndpoint:54 - Registering block manager user-PC:62456 with 1965.3 MB RAM, BlockManagerId(driver, user-PC, 62456, None)
2019-10-02 18:51:24 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, user-PC, 62456, None)
2019-10-02 18:51:24 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, user-PC, 62456, None)
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@675d8c96{/metrics/json,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:///C:/temp').
2019-10-02 18:51:24 INFO  SharedState:54 - Warehouse path is 'file:///C:/temp'.
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@79e18e38{/SQL,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29a60c27{/SQL/json,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5fcacc0{/SQL/execution,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@533b266e{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-10-02 18:51:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a988392{/static/sql,null,AVAILABLE,@Spark}
2019-10-02 18:51:25 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2019-10-02 18:51:26 INFO  HiveUtils:54 - Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
2019-10-02 18:51:27 INFO  HiveMetaStore:589 - 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
2019-10-02 18:51:27 INFO  ObjectStore:289 - ObjectStore, initialize called
2019-10-02 18:51:27 INFO  Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2019-10-02 18:51:27 INFO  Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2019-10-02 18:51:29 INFO  ObjectStore:370 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2019-10-02 18:51:30 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
2019-10-02 18:51:30 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
2019-10-02 18:51:30 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
2019-10-02 18:51:30 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
2019-10-02 18:51:31 INFO  Query:77 - Reading in results for query "org.datanucleus.store.rdbms.query.SQLQuery@0" since the connection used is closing
2019-10-02 18:51:31 INFO  MetaStoreDirectSql:139 - Using direct SQL, underlying DB is DERBY
2019-10-02 18:51:31 INFO  ObjectStore:272 - Initialized ObjectStore
2019-10-02 18:51:31 INFO  HiveMetaStore:663 - Added admin role in metastore
2019-10-02 18:51:31 INFO  HiveMetaStore:672 - Added public role in metastore
2019-10-02 18:51:31 INFO  HiveMetaStore:712 - No user is added in admin role, since config is empty
2019-10-02 18:51:31 INFO  HiveMetaStore:746 - 0: get_all_databases
2019-10-02 18:51:31 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_all_databases	
2019-10-02 18:51:31 INFO  HiveMetaStore:746 - 0: get_functions: db=default pat=*
2019-10-02 18:51:31 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
2019-10-02 18:51:31 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
2019-10-02 18:51:31 INFO  SessionState:641 - Created local directory: C:/Users/user/AppData/Local/Temp/504b278a-6613-49b5-95bd-223e5c271381_resources
2019-10-02 18:51:31 INFO  SessionState:641 - Created HDFS directory: /tmp/hive/user/504b278a-6613-49b5-95bd-223e5c271381
2019-10-02 18:51:31 INFO  SessionState:641 - Created local directory: C:/Users/user/AppData/Local/Temp/user/504b278a-6613-49b5-95bd-223e5c271381
2019-10-02 18:51:31 INFO  SessionState:641 - Created HDFS directory: /tmp/hive/user/504b278a-6613-49b5-95bd-223e5c271381/_tmp_space.db
2019-10-02 18:51:31 INFO  HiveClientImpl:54 - Warehouse location for Hive client (version 1.2.2) is file:///C:/temp
2019-10-02 18:51:31 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:31 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:31 INFO  HiveMetaStore:746 - 0: get_database: global_temp
2019-10-02 18:51:31 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: global_temp	
2019-10-02 18:51:31 WARN  ObjectStore:568 - Failed to get database global_temp, returning NoSuchObjectException
2019-10-02 18:51:33 WARN  SetCommand:66 - 'SET hive.exec.dynamic.partition=true' might not work, since Spark doesn't support changing the Hive config dynamically. Please pass the Hive-specific config by adding the prefix spark.hadoop (e.g. spark.hadoop.hive.exec.dynamic.partition) when starting a Spark application. For details, see the link: https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties.
2019-10-02 18:51:33 WARN  SetCommand:66 - 'SET hive.exec.dynamic.partition.mode=nonstrict' might not work, since Spark doesn't support changing the Hive config dynamically. Please pass the Hive-specific config by adding the prefix spark.hadoop (e.g. spark.hadoop.hive.exec.dynamic.partition.mode) when starting a Spark application. For details, see the link: https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties.
2019-10-02 18:51:33 WARN  SetCommand:66 - 'SET hive.auto.convert.join=true' might not work, since Spark doesn't support changing the Hive config dynamically. Please pass the Hive-specific config by adding the prefix spark.hadoop (e.g. spark.hadoop.hive.auto.convert.join) when starting a Spark application. For details, see the link: https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties.
2019-10-02 18:51:33 WARN  SetCommand:66 - 'SET hive.enforce.bucketmap.join=true' might not work, since Spark doesn't support changing the Hive config dynamically. Please pass the Hive-specific config by adding the prefix spark.hadoop (e.g. spark.hadoop.hive.enforce.bucketmap.join) when starting a Spark application. For details, see the link: https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties.
2019-10-02 18:51:33 WARN  SetCommand:66 - 'SET hive.optimize.bucketmap.join=true' might not work, since Spark doesn't support changing the Hive config dynamically. Please pass the Hive-specific config by adding the prefix spark.hadoop (e.g. spark.hadoop.hive.optimize.bucketmap.join) when starting a Spark application. For details, see the link: https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties.
2019-10-02 18:51:33 WARN  SetCommand:66 - 'SET hive.exec.parallel=true' might not work, since Spark doesn't support changing the Hive config dynamically. Please pass the Hive-specific config by adding the prefix spark.hadoop (e.g. spark.hadoop.hive.exec.parallel) when starting a Spark application. For details, see the link: https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties.
2019-10-02 18:51:33 WARN  SetCommand:66 - 'SET hive.execution.engine=tez' might not work, since Spark doesn't support changing the Hive config dynamically. Please pass the Hive-specific config by adding the prefix spark.hadoop (e.g. spark.hadoop.hive.execution.engine) when starting a Spark application. For details, see the link: https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties.
2019-10-02 18:51:33 WARN  SetCommand:66 - 'SET hive.vectorized.execution.enabled=true' might not work, since Spark doesn't support changing the Hive config dynamically. Please pass the Hive-specific config by adding the prefix spark.hadoop (e.g. spark.hadoop.hive.vectorized.execution.enabled) when starting a Spark application. For details, see the link: https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties.
2019-10-02 18:51:33 WARN  SetCommand:66 - 'SET hive.vectorized.execution.reduce.enabled=true' might not work, since Spark doesn't support changing the Hive config dynamically. Please pass the Hive-specific config by adding the prefix spark.hadoop (e.g. spark.hadoop.hive.vectorized.execution.reduce.enabled) when starting a Spark application. For details, see the link: https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties.
2019-10-02 18:51:34 INFO  Utils$:51 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Accident_Severity_Code.csv)- Started @ 2019-10-02T18:51:34.077
2019-10-02 18:51:34 INFO  Utils$:58 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Accident_Severity_Code.csv)- Completed @ 2019-10-02T18:51:34.331
2019-10-02 18:51:34 INFO  Utils$:67 - Utils.OverwriteTable(Accident_Severity_Code)- Started @ 2019-10-02T18:51:34.616
2019-10-02 18:51:34 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=accident_severity_code
2019-10-02 18:51:34 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=accident_severity_code	
2019-10-02 18:51:34 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:34 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:34 INFO  FileSourceStrategy:54 - Output Data Schema: struct<Type_Code: smallint, Type: string>
2019-10-02 18:51:34 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:35 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=accident_severity_code
2019-10-02 18:51:35 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=accident_severity_code	
2019-10-02 18:51:35 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:35 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:35 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:35 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:35 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:35 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:35 INFO  CodeGenerator:54 - Code generated in 487.895465 ms
2019-10-02 18:51:36 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 293.7 KB, free 1965.0 MB)
2019-10-02 18:51:36 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1965.0 MB)
2019-10-02 18:51:36 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.3 MB)
2019-10-02 18:51:36 INFO  SparkContext:54 - Created broadcast 0 from saveAsTable at Utils.scala:76
2019-10-02 18:51:36 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:36 INFO  SparkContext:54 - Starting job: saveAsTable at Utils.scala:76
2019-10-02 18:51:36 INFO  DAGScheduler:54 - Got job 0 (saveAsTable at Utils.scala:76) with 1 output partitions
2019-10-02 18:51:36 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (saveAsTable at Utils.scala:76)
2019-10-02 18:51:36 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-10-02 18:51:36 INFO  DAGScheduler:54 - Missing parents: List()
2019-10-02 18:51:36 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[2] at saveAsTable at Utils.scala:76), which has no missing parents
2019-10-02 18:51:36 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 158.1 KB, free 1964.8 MB)
2019-10-02 18:51:36 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 58.2 KB, free 1964.8 MB)
2019-10-02 18:51:36 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on user-PC:62456 (size: 58.2 KB, free: 1965.2 MB)
2019-10-02 18:51:36 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:36 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at saveAsTable at Utils.scala:76) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:36 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2019-10-02 18:51:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8379 bytes)
2019-10-02 18:51:37 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-10-02 18:51:37 INFO  CodeGenerator:54 - Code generated in 34.241926 ms
2019-10-02 18:51:37 INFO  CodeGenerator:54 - Code generated in 21.219249 ms
2019-10-02 18:51:37 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Accident_Severity_Code.csv, range: 0-42, partition values: [empty row]
2019-10-02 18:51:37 INFO  CodeGenerator:54 - Code generated in 22.716391 ms
2019-10-02 18:51:37 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:37 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:37 INFO  CodeGenerator:54 - Code generated in 15.4721 ms
2019-10-02 18:51:37 INFO  CodeGenerator:54 - Code generated in 29.282394 ms
2019-10-02 18:51:38 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20191002185137_0000_m_000000_0' to file:/C:/temp/accident_severity_code/_temporary/0/task_20191002185137_0000_m_000000
2019-10-02 18:51:38 INFO  SparkHadoopMapRedUtil:54 - attempt_20191002185137_0000_m_000000_0: Committed
2019-10-02 18:51:38 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2892 bytes result sent to driver
2019-10-02 18:51:38 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 1164 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:38 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-10-02 18:51:38 INFO  DAGScheduler:54 - ResultStage 0 (saveAsTable at Utils.scala:76) finished in 1.387 s
2019-10-02 18:51:38 INFO  DAGScheduler:54 - Job 0 finished: saveAsTable at Utils.scala:76, took 1.465002 s
2019-10-02 18:51:38 INFO  FileFormatWriter:54 - Job null committed.
2019-10-02 18:51:38 INFO  FileFormatWriter:54 - Finished processing stats for job null.
2019-10-02 18:51:38 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:38 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:38 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:38 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:38 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=accident_severity_code
2019-10-02 18:51:38 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=accident_severity_code	
2019-10-02 18:51:38 INFO  HiveExternalCatalog:54 - Persisting file based data source table `default`.`accident_severity_code` into Hive metastore in Hive compatible format.
2019-10-02 18:51:38 INFO  HiveMetaStore:746 - 0: create_table: Table(tableName:accident_severity_code, dbName:default, owner:user, createTime:1570038694, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/accident_severity_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
2019-10-02 18:51:38 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=create_table: Table(tableName:accident_severity_code, dbName:default, owner:user, createTime:1570038694, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/accident_severity_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 31
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 32
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 11
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 24
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 36
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 19
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 28
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 25
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 35
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 10
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 34
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 9
2019-10-02 18:51:38 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on user-PC:62456 in memory (size: 58.2 KB, free: 1965.3 MB)
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 20
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 40
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 18
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 14
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 22
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 13
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 38
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 37
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 15
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 26
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 33
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 23
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 17
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 29
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 21
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 30
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 27
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 12
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 16
2019-10-02 18:51:38 INFO  ContextCleaner:54 - Cleaned accumulator 39
2019-10-02 18:51:39 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:39 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:39 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=accident_severity_code
2019-10-02 18:51:39 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=accident_severity_code	
2019-10-02 18:51:39 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=accident_severity_code
2019-10-02 18:51:39 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=accident_severity_code	
2019-10-02 18:51:39 INFO  AlterTableRecoverPartitionsCommand:54 - Recover all the partitions in file:/C:/temp/accident_severity_code
2019-10-02 18:51:39 INFO  AlterTableRecoverPartitionsCommand:54 - Found 1 partitions in file:/C:/temp/accident_severity_code
2019-10-02 18:51:39 INFO  AlterTableRecoverPartitionsCommand:54 - Finished to gather the fast stats for all 1 partitions.
2019-10-02 18:51:39 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:39 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:39 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=accident_severity_code
2019-10-02 18:51:39 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=accident_severity_code	
2019-10-02 18:51:39 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:39 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:39 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=accident_severity_code
2019-10-02 18:51:39 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=accident_severity_code	
2019-10-02 18:51:39 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=accident_severity_code
2019-10-02 18:51:39 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=accident_severity_code	
2019-10-02 18:51:39 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=accident_severity_code
2019-10-02 18:51:39 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=accident_severity_code	
2019-10-02 18:51:39 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=accident_severity_code
2019-10-02 18:51:39 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=accident_severity_code	
2019-10-02 18:51:39 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=accident_severity_code
2019-10-02 18:51:39 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=accident_severity_code	
2019-10-02 18:51:39 INFO  HiveMetaStore:746 - 0: add_partitions
2019-10-02 18:51:39 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=add_partitions	
2019-10-02 18:51:39 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:39 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:39 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=accident_severity_code
2019-10-02 18:51:39 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=accident_severity_code	
2019-10-02 18:51:39 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=accident_severity_code
2019-10-02 18:51:39 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=accident_severity_code	
2019-10-02 18:51:39 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=accident_severity_code
2019-10-02 18:51:39 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=accident_severity_code	
2019-10-02 18:51:39 INFO  HiveMetaStore:746 - 0: alter_table: db=default tbl=accident_severity_code newtbl=accident_severity_code
2019-10-02 18:51:39 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=accident_severity_code newtbl=accident_severity_code	
2019-10-02 18:51:40 INFO  AlterTableRecoverPartitionsCommand:54 - Recovered all partitions (1).
2019-10-02 18:51:40 INFO  Utils$:77 - Utils.OverwriteTable(Accident_Severity_Code)- Completed @ 2019-10-02T18:51:40.130
2019-10-02 18:51:40 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:40 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:40 INFO  FileSourceStrategy:54 - Output Data Schema: struct<>
2019-10-02 18:51:40 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:40 INFO  CodeGenerator:54 - Code generated in 53.470044 ms
2019-10-02 18:51:40 INFO  CodeGenerator:54 - Code generated in 61.57335 ms
2019-10-02 18:51:40 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 293.7 KB, free 1964.7 MB)
2019-10-02 18:51:40 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1964.7 MB)
2019-10-02 18:51:40 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.3 MB)
2019-10-02 18:51:40 INFO  SparkContext:54 - Created broadcast 2 from count at ReferenceData.scala:42
2019-10-02 18:51:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:40 INFO  SparkContext:54 - Starting job: count at ReferenceData.scala:42
2019-10-02 18:51:40 INFO  DAGScheduler:54 - Registering RDD 7 (count at ReferenceData.scala:42)
2019-10-02 18:51:40 INFO  DAGScheduler:54 - Got job 1 (count at ReferenceData.scala:42) with 1 output partitions
2019-10-02 18:51:40 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (count at ReferenceData.scala:42)
2019-10-02 18:51:40 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 1)
2019-10-02 18:51:40 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 1)
2019-10-02 18:51:40 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:40 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 14.4 KB, free 1964.7 MB)
2019-10-02 18:51:40 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1964.7 MB)
2019-10-02 18:51:40 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on user-PC:62456 (size: 8.1 KB, free: 1965.2 MB)
2019-10-02 18:51:40 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:40 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:40 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2019-10-02 18:51:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8368 bytes)
2019-10-02 18:51:40 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2019-10-02 18:51:40 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Accident_Severity_Code.csv, range: 0-42, partition values: [empty row]
2019-10-02 18:51:40 INFO  CodeGenerator:54 - Code generated in 9.300574 ms
2019-10-02 18:51:40 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1583 bytes result sent to driver
2019-10-02 18:51:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 113 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:40 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-10-02 18:51:40 INFO  DAGScheduler:54 - ShuffleMapStage 1 (count at ReferenceData.scala:42) finished in 0.133 s
2019-10-02 18:51:40 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-10-02 18:51:40 INFO  DAGScheduler:54 - running: Set()
2019-10-02 18:51:40 INFO  DAGScheduler:54 - waiting: Set(ResultStage 2)
2019-10-02 18:51:40 INFO  DAGScheduler:54 - failed: Set()
2019-10-02 18:51:40 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[10] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:40 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 7.3 KB, free 1964.7 MB)
2019-10-02 18:51:40 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1964.6 MB)
2019-10-02 18:51:40 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on user-PC:62456 (size: 3.8 KB, free: 1965.2 MB)
2019-10-02 18:51:40 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:40 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:40 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2019-10-02 18:51:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 7754 bytes)
2019-10-02 18:51:40 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2019-10-02 18:51:40 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2019-10-02 18:51:40 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 13 ms
2019-10-02 18:51:40 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1782 bytes result sent to driver
2019-10-02 18:51:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 82 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:40 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-10-02 18:51:40 INFO  DAGScheduler:54 - ResultStage 2 (count at ReferenceData.scala:42) finished in 0.102 s
2019-10-02 18:51:40 INFO  DAGScheduler:54 - Job 1 finished: count at ReferenceData.scala:42, took 0.274302 s
---------------------------------------------------------------------------------------------------------
The Reference Table :Accident_Severity_Code : Loaded into HIVE with counts of 3
---------------------------------------------------------------------------------------------------------
2019-10-02 18:51:40 INFO  Utils$:51 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Age_Band_of_Driver_Code.csv)- Started @ 2019-10-02T18:51:40.844
2019-10-02 18:51:40 INFO  Utils$:58 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Age_Band_of_Driver_Code.csv)- Completed @ 2019-10-02T18:51:40.865
2019-10-02 18:51:40 INFO  Utils$:67 - Utils.OverwriteTable(Age_Band_of_Driver_Code)- Started @ 2019-10-02T18:51:40.941
2019-10-02 18:51:40 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:40 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:41 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:41 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:41 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:41 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:41 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:41 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:41 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:41 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:41 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:41 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:41 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:41 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:41 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:41 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:41 INFO  HiveMetaStore:746 - 0: drop_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:41 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:41 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
2019-10-02 18:51:41 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
2019-10-02 18:51:41 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
2019-10-02 18:51:41 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
2019-10-02 18:51:41 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
2019-10-02 18:51:41 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
2019-10-02 18:51:42 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
2019-10-02 18:51:42 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
2019-10-02 18:51:42 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
2019-10-02 18:51:42 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
2019-10-02 18:51:42 INFO  hivemetastoressimpl:41 - deleting  file:/C:/temp/age_band_of_driver_code
2019-10-02 18:51:42 INFO  deprecation:1173 - io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
2019-10-02 18:51:42 INFO  TrashPolicyDefault:92 - Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2019-10-02 18:51:42 INFO  hivemetastoressimpl:53 - Deleted the diretory file:/C:/temp/age_band_of_driver_code
2019-10-02 18:51:42 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:42 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:42 INFO  FileSourceStrategy:54 - Output Data Schema: struct<Type_Code: smallint, Type: string>
2019-10-02 18:51:42 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:42 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:42 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:42 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:42 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:42 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:42 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:42 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:42 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:42 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 293.7 KB, free 1964.4 MB)
2019-10-02 18:51:42 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1964.3 MB)
2019-10-02 18:51:42 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.2 MB)
2019-10-02 18:51:42 INFO  SparkContext:54 - Created broadcast 5 from saveAsTable at Utils.scala:76
2019-10-02 18:51:42 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:42 INFO  SparkContext:54 - Starting job: saveAsTable at Utils.scala:76
2019-10-02 18:51:42 INFO  DAGScheduler:54 - Got job 2 (saveAsTable at Utils.scala:76) with 1 output partitions
2019-10-02 18:51:42 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (saveAsTable at Utils.scala:76)
2019-10-02 18:51:42 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-10-02 18:51:42 INFO  DAGScheduler:54 - Missing parents: List()
2019-10-02 18:51:42 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[13] at saveAsTable at Utils.scala:76), which has no missing parents
2019-10-02 18:51:42 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 158.1 KB, free 1964.2 MB)
2019-10-02 18:51:42 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 58.2 KB, free 1964.1 MB)
2019-10-02 18:51:42 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on user-PC:62456 (size: 58.2 KB, free: 1965.2 MB)
2019-10-02 18:51:42 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:42 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at saveAsTable at Utils.scala:76) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:42 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2019-10-02 18:51:42 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8380 bytes)
2019-10-02 18:51:42 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2019-10-02 18:51:42 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Age_Band_of_Driver_Code.csv, range: 0-165, partition values: [empty row]
2019-10-02 18:51:42 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:42 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:43 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20191002185142_0003_m_000000_0' to file:/C:/temp/age_band_of_driver_code/_temporary/0/task_20191002185142_0003_m_000000
2019-10-02 18:51:43 INFO  SparkHadoopMapRedUtil:54 - attempt_20191002185142_0003_m_000000_0: Committed
2019-10-02 18:51:43 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 2892 bytes result sent to driver
2019-10-02 18:51:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 194 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:43 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2019-10-02 18:51:43 INFO  DAGScheduler:54 - ResultStage 3 (saveAsTable at Utils.scala:76) finished in 0.243 s
2019-10-02 18:51:43 INFO  DAGScheduler:54 - Job 2 finished: saveAsTable at Utils.scala:76, took 0.249438 s
2019-10-02 18:51:43 INFO  FileFormatWriter:54 - Job null committed.
2019-10-02 18:51:43 INFO  FileFormatWriter:54 - Finished processing stats for job null.
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:43 INFO  HiveExternalCatalog:54 - Persisting file based data source table `default`.`age_band_of_driver_code` into Hive metastore in Hive compatible format.
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: create_table: Table(tableName:age_band_of_driver_code, dbName:default, owner:user, createTime:1570038702, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/age_band_of_driver_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=create_table: Table(tableName:age_band_of_driver_code, dbName:default, owner:user, createTime:1570038702, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/age_band_of_driver_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:43 INFO  AlterTableRecoverPartitionsCommand:54 - Recover all the partitions in file:/C:/temp/age_band_of_driver_code
2019-10-02 18:51:43 INFO  AlterTableRecoverPartitionsCommand:54 - Found 1 partitions in file:/C:/temp/age_band_of_driver_code
2019-10-02 18:51:43 INFO  AlterTableRecoverPartitionsCommand:54 - Finished to gather the fast stats for all 1 partitions.
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: add_partitions
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=add_partitions	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=age_band_of_driver_code
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=age_band_of_driver_code	
2019-10-02 18:51:43 INFO  HiveMetaStore:746 - 0: alter_table: db=default tbl=age_band_of_driver_code newtbl=age_band_of_driver_code
2019-10-02 18:51:43 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=age_band_of_driver_code newtbl=age_band_of_driver_code	
2019-10-02 18:51:43 INFO  AlterTableRecoverPartitionsCommand:54 - Recovered all partitions (1).
2019-10-02 18:51:43 INFO  Utils$:77 - Utils.OverwriteTable(Age_Band_of_Driver_Code)- Completed @ 2019-10-02T18:51:43.617
2019-10-02 18:51:43 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:43 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:43 INFO  FileSourceStrategy:54 - Output Data Schema: struct<>
2019-10-02 18:51:43 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:43 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 293.7 KB, free 1963.8 MB)
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 133
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 86
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 130
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 89
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 114
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 85
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 149
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 61
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 56
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 77
2019-10-02 18:51:43 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1963.8 MB)
2019-10-02 18:51:43 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.1 MB)
2019-10-02 18:51:43 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on user-PC:62456 in memory (size: 3.8 KB, free: 1965.1 MB)
2019-10-02 18:51:43 INFO  SparkContext:54 - Created broadcast 7 from count at ReferenceData.scala:42
2019-10-02 18:51:43 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 112
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 126
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 111
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 147
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 83
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 51
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 127
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 137
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 68
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 142
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 41
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 101
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 150
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 140
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 43
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 90
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 55
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 59
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 107
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 120
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 123
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 48
2019-10-02 18:51:43 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on user-PC:62456 in memory (size: 8.1 KB, free: 1965.1 MB)
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 128
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 136
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 132
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 87
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 134
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 116
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 138
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 88
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 75
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 148
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 74
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 131
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 99
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 118
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 141
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 93
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 44
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 106
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 100
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 115
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 113
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 45
2019-10-02 18:51:43 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on user-PC:62456 in memory (size: 58.2 KB, free: 1965.2 MB)
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 146
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 47
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 52
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 139
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 129
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 81
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 50
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 144
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 79
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 78
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 119
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 71
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 102
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 91
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 82
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 92
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 97
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 57
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 70
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 110
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 46
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 54
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 84
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 135
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 122
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 108
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 121
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 64
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 95
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 69
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 117
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 42
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 80
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 105
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 109
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 73
2019-10-02 18:51:43 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1965.2 MB)
2019-10-02 18:51:43 INFO  SparkContext:54 - Starting job: count at ReferenceData.scala:42
2019-10-02 18:51:43 INFO  DAGScheduler:54 - Registering RDD 18 (count at ReferenceData.scala:42)
2019-10-02 18:51:43 INFO  DAGScheduler:54 - Got job 3 (count at ReferenceData.scala:42) with 1 output partitions
2019-10-02 18:51:43 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (count at ReferenceData.scala:42)
2019-10-02 18:51:43 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2019-10-02 18:51:43 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2019-10-02 18:51:43 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[18] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:43 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 14.4 KB, free 1964.4 MB)
2019-10-02 18:51:43 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1964.3 MB)
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 143
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 62
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 96
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 49
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 63
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 72
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 103
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 65
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 104
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 58
2019-10-02 18:51:43 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on user-PC:62456 (size: 8.1 KB, free: 1965.2 MB)
2019-10-02 18:51:43 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[18] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:43 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2019-10-02 18:51:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8369 bytes)
2019-10-02 18:51:43 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2019-10-02 18:51:43 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Age_Band_of_Driver_Code.csv, range: 0-165, partition values: [empty row]
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned shuffle 0
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 94
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 66
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 125
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 67
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 76
2019-10-02 18:51:43 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1965.2 MB)
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 98
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 60
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 53
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 145
2019-10-02 18:51:43 INFO  ContextCleaner:54 - Cleaned accumulator 124
2019-10-02 18:51:43 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1540 bytes result sent to driver
2019-10-02 18:51:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 49 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:43 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2019-10-02 18:51:43 INFO  DAGScheduler:54 - ShuffleMapStage 4 (count at ReferenceData.scala:42) finished in 0.066 s
2019-10-02 18:51:43 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-10-02 18:51:43 INFO  DAGScheduler:54 - running: Set()
2019-10-02 18:51:43 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2019-10-02 18:51:43 INFO  DAGScheduler:54 - failed: Set()
2019-10-02 18:51:43 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[21] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:43 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 7.3 KB, free 1964.7 MB)
2019-10-02 18:51:43 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1964.6 MB)
2019-10-02 18:51:43 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on user-PC:62456 (size: 3.8 KB, free: 1965.2 MB)
2019-10-02 18:51:43 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:43 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2019-10-02 18:51:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, ANY, 7754 bytes)
2019-10-02 18:51:43 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2019-10-02 18:51:43 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2019-10-02 18:51:43 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-10-02 18:51:43 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 1696 bytes result sent to driver
2019-10-02 18:51:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 23 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:43 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2019-10-02 18:51:43 INFO  DAGScheduler:54 - ResultStage 5 (count at ReferenceData.scala:42) finished in 0.035 s
2019-10-02 18:51:43 INFO  DAGScheduler:54 - Job 3 finished: count at ReferenceData.scala:42, took 0.108464 s
---------------------------------------------------------------------------------------------------------
The Reference Table :Age_Band_of_Driver_Code : Loaded into HIVE with counts of 12
---------------------------------------------------------------------------------------------------------
2019-10-02 18:51:43 INFO  Utils$:51 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Casualty_Class_Code.csv)- Started @ 2019-10-02T18:51:43.994
2019-10-02 18:51:44 INFO  Utils$:58 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Casualty_Class_Code.csv)- Completed @ 2019-10-02T18:51:44.011
2019-10-02 18:51:44 INFO  Utils$:67 - Utils.OverwriteTable(Casualty_Class_Code)- Started @ 2019-10-02T18:51:44.094
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: drop_table : db=default tbl=casualty_class_code
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:44 INFO  hivemetastoressimpl:41 - deleting  file:/C:/temp/casualty_class_code
2019-10-02 18:51:44 INFO  TrashPolicyDefault:92 - Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2019-10-02 18:51:44 INFO  hivemetastoressimpl:53 - Deleted the diretory file:/C:/temp/casualty_class_code
2019-10-02 18:51:44 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:44 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:44 INFO  FileSourceStrategy:54 - Output Data Schema: struct<Type_Code: smallint, Type: string>
2019-10-02 18:51:44 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:44 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:44 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:44 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 293.7 KB, free 1964.4 MB)
2019-10-02 18:51:44 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1964.3 MB)
2019-10-02 18:51:44 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.2 MB)
2019-10-02 18:51:44 INFO  SparkContext:54 - Created broadcast 10 from saveAsTable at Utils.scala:76
2019-10-02 18:51:44 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:44 INFO  SparkContext:54 - Starting job: saveAsTable at Utils.scala:76
2019-10-02 18:51:44 INFO  DAGScheduler:54 - Got job 4 (saveAsTable at Utils.scala:76) with 1 output partitions
2019-10-02 18:51:44 INFO  DAGScheduler:54 - Final stage: ResultStage 6 (saveAsTable at Utils.scala:76)
2019-10-02 18:51:44 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-10-02 18:51:44 INFO  DAGScheduler:54 - Missing parents: List()
2019-10-02 18:51:44 INFO  DAGScheduler:54 - Submitting ResultStage 6 (MapPartitionsRDD[24] at saveAsTable at Utils.scala:76), which has no missing parents
2019-10-02 18:51:44 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 158.1 KB, free 1964.2 MB)
2019-10-02 18:51:44 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 58.2 KB, free 1964.1 MB)
2019-10-02 18:51:44 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on user-PC:62456 (size: 58.2 KB, free: 1965.2 MB)
2019-10-02 18:51:44 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:44 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at saveAsTable at Utils.scala:76) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:44 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 1 tasks
2019-10-02 18:51:44 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8376 bytes)
2019-10-02 18:51:44 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 6)
2019-10-02 18:51:44 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Casualty_Class_Code.csv, range: 0-58, partition values: [empty row]
2019-10-02 18:51:44 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:44 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:44 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20191002185144_0006_m_000000_0' to file:/C:/temp/casualty_class_code/_temporary/0/task_20191002185144_0006_m_000000
2019-10-02 18:51:44 INFO  SparkHadoopMapRedUtil:54 - attempt_20191002185144_0006_m_000000_0: Committed
2019-10-02 18:51:44 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 6). 2849 bytes result sent to driver
2019-10-02 18:51:44 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 6) in 152 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:44 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2019-10-02 18:51:44 INFO  DAGScheduler:54 - ResultStage 6 (saveAsTable at Utils.scala:76) finished in 0.193 s
2019-10-02 18:51:44 INFO  DAGScheduler:54 - Job 4 finished: saveAsTable at Utils.scala:76, took 0.195458 s
2019-10-02 18:51:44 INFO  FileFormatWriter:54 - Job null committed.
2019-10-02 18:51:44 INFO  FileFormatWriter:54 - Finished processing stats for job null.
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:44 INFO  HiveExternalCatalog:54 - Persisting file based data source table `default`.`casualty_class_code` into Hive metastore in Hive compatible format.
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: create_table: Table(tableName:casualty_class_code, dbName:default, owner:user, createTime:1570038704, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/casualty_class_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=create_table: Table(tableName:casualty_class_code, dbName:default, owner:user, createTime:1570038704, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/casualty_class_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:44 INFO  AlterTableRecoverPartitionsCommand:54 - Recover all the partitions in file:/C:/temp/casualty_class_code
2019-10-02 18:51:44 INFO  AlterTableRecoverPartitionsCommand:54 - Found 1 partitions in file:/C:/temp/casualty_class_code
2019-10-02 18:51:44 INFO  AlterTableRecoverPartitionsCommand:54 - Finished to gather the fast stats for all 1 partitions.
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:44 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:44 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: add_partitions
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=add_partitions	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_class_code
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_class_code	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: alter_table: db=default tbl=casualty_class_code newtbl=casualty_class_code
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=casualty_class_code newtbl=casualty_class_code	
2019-10-02 18:51:45 INFO  AlterTableRecoverPartitionsCommand:54 - Recovered all partitions (1).
2019-10-02 18:51:45 INFO  Utils$:77 - Utils.OverwriteTable(Casualty_Class_Code)- Completed @ 2019-10-02T18:51:45.190
2019-10-02 18:51:45 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:45 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:45 INFO  FileSourceStrategy:54 - Output Data Schema: struct<>
2019-10-02 18:51:45 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:45 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 293.7 KB, free 1963.8 MB)
2019-10-02 18:51:45 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1963.8 MB)
2019-10-02 18:51:45 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.1 MB)
2019-10-02 18:51:45 INFO  SparkContext:54 - Created broadcast 12 from count at ReferenceData.scala:42
2019-10-02 18:51:45 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:45 INFO  SparkContext:54 - Starting job: count at ReferenceData.scala:42
2019-10-02 18:51:45 INFO  DAGScheduler:54 - Registering RDD 29 (count at ReferenceData.scala:42)
2019-10-02 18:51:45 INFO  DAGScheduler:54 - Got job 5 (count at ReferenceData.scala:42) with 1 output partitions
2019-10-02 18:51:45 INFO  DAGScheduler:54 - Final stage: ResultStage 8 (count at ReferenceData.scala:42)
2019-10-02 18:51:45 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 7)
2019-10-02 18:51:45 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 7)
2019-10-02 18:51:45 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 7 (MapPartitionsRDD[29] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:45 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 14.4 KB, free 1963.8 MB)
2019-10-02 18:51:45 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1963.8 MB)
2019-10-02 18:51:45 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on user-PC:62456 (size: 8.1 KB, free: 1965.1 MB)
2019-10-02 18:51:45 INFO  SparkContext:54 - Created broadcast 13 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:45 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[29] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:45 INFO  TaskSchedulerImpl:54 - Adding task set 7.0 with 1 tasks
2019-10-02 18:51:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8365 bytes)
2019-10-02 18:51:45 INFO  Executor:54 - Running task 0.0 in stage 7.0 (TID 7)
2019-10-02 18:51:45 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Casualty_Class_Code.csv, range: 0-58, partition values: [empty row]
2019-10-02 18:51:45 INFO  Executor:54 - Finished task 0.0 in stage 7.0 (TID 7). 1583 bytes result sent to driver
2019-10-02 18:51:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 7) in 37 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:45 INFO  TaskSchedulerImpl:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2019-10-02 18:51:45 INFO  DAGScheduler:54 - ShuffleMapStage 7 (count at ReferenceData.scala:42) finished in 0.050 s
2019-10-02 18:51:45 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-10-02 18:51:45 INFO  DAGScheduler:54 - running: Set()
2019-10-02 18:51:45 INFO  DAGScheduler:54 - waiting: Set(ResultStage 8)
2019-10-02 18:51:45 INFO  DAGScheduler:54 - failed: Set()
2019-10-02 18:51:45 INFO  DAGScheduler:54 - Submitting ResultStage 8 (MapPartitionsRDD[32] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:45 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 7.3 KB, free 1963.8 MB)
2019-10-02 18:51:45 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1963.8 MB)
2019-10-02 18:51:45 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on user-PC:62456 (size: 3.8 KB, free: 1965.1 MB)
2019-10-02 18:51:45 INFO  SparkContext:54 - Created broadcast 14 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:45 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[32] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:45 INFO  TaskSchedulerImpl:54 - Adding task set 8.0 with 1 tasks
2019-10-02 18:51:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, ANY, 7754 bytes)
2019-10-02 18:51:45 INFO  Executor:54 - Running task 0.0 in stage 8.0 (TID 8)
2019-10-02 18:51:45 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2019-10-02 18:51:45 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2019-10-02 18:51:45 INFO  Executor:54 - Finished task 0.0 in stage 8.0 (TID 8). 1782 bytes result sent to driver
2019-10-02 18:51:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 8.0 (TID 8) in 15 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:45 INFO  TaskSchedulerImpl:54 - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2019-10-02 18:51:45 INFO  DAGScheduler:54 - ResultStage 8 (count at ReferenceData.scala:42) finished in 0.026 s
2019-10-02 18:51:45 INFO  DAGScheduler:54 - Job 5 finished: count at ReferenceData.scala:42, took 0.084947 s
---------------------------------------------------------------------------------------------------------
The Reference Table :Casualty_Class_Code : Loaded into HIVE with counts of 3
---------------------------------------------------------------------------------------------------------
2019-10-02 18:51:45 INFO  Utils$:51 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Casualty_Severity_Code.csv)- Started @ 2019-10-02T18:51:45.443
2019-10-02 18:51:45 INFO  Utils$:58 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Casualty_Severity_Code.csv)- Completed @ 2019-10-02T18:51:45.463
2019-10-02 18:51:45 INFO  Utils$:67 - Utils.OverwriteTable(Casualty_Severity_Code)- Started @ 2019-10-02T18:51:45.508
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: drop_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:45 INFO  hivemetastoressimpl:41 - deleting  file:/C:/temp/casualty_severity_code
2019-10-02 18:51:45 INFO  TrashPolicyDefault:92 - Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2019-10-02 18:51:45 INFO  hivemetastoressimpl:53 - Deleted the diretory file:/C:/temp/casualty_severity_code
2019-10-02 18:51:45 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:45 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:45 INFO  FileSourceStrategy:54 - Output Data Schema: struct<Type_Code: smallint, Type: string>
2019-10-02 18:51:45 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:45 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:45 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:45 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:45 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:45 INFO  MemoryStore:54 - Block broadcast_15 stored as values in memory (estimated size 293.7 KB, free 1963.5 MB)
2019-10-02 18:51:45 INFO  MemoryStore:54 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1963.5 MB)
2019-10-02 18:51:45 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.1 MB)
2019-10-02 18:51:45 INFO  SparkContext:54 - Created broadcast 15 from saveAsTable at Utils.scala:76
2019-10-02 18:51:45 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:45 INFO  SparkContext:54 - Starting job: saveAsTable at Utils.scala:76
2019-10-02 18:51:45 INFO  DAGScheduler:54 - Got job 6 (saveAsTable at Utils.scala:76) with 1 output partitions
2019-10-02 18:51:45 INFO  DAGScheduler:54 - Final stage: ResultStage 9 (saveAsTable at Utils.scala:76)
2019-10-02 18:51:45 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-10-02 18:51:45 INFO  DAGScheduler:54 - Missing parents: List()
2019-10-02 18:51:45 INFO  DAGScheduler:54 - Submitting ResultStage 9 (MapPartitionsRDD[35] at saveAsTable at Utils.scala:76), which has no missing parents
2019-10-02 18:51:45 INFO  MemoryStore:54 - Block broadcast_16 stored as values in memory (estimated size 158.1 KB, free 1963.3 MB)
2019-10-02 18:51:45 INFO  MemoryStore:54 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 58.2 KB, free 1963.3 MB)
2019-10-02 18:51:45 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on user-PC:62456 (size: 58.2 KB, free: 1965.0 MB)
2019-10-02 18:51:45 INFO  SparkContext:54 - Created broadcast 16 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:45 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[35] at saveAsTable at Utils.scala:76) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:45 INFO  TaskSchedulerImpl:54 - Adding task set 9.0 with 1 tasks
2019-10-02 18:51:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 8379 bytes)
2019-10-02 18:51:45 INFO  Executor:54 - Running task 0.0 in stage 9.0 (TID 9)
2019-10-02 18:51:45 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Casualty_Severity_Code.csv, range: 0-42, partition values: [empty row]
2019-10-02 18:51:45 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:45 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:46 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20191002185145_0009_m_000000_0' to file:/C:/temp/casualty_severity_code/_temporary/0/task_20191002185145_0009_m_000000
2019-10-02 18:51:46 INFO  SparkHadoopMapRedUtil:54 - attempt_20191002185145_0009_m_000000_0: Committed
2019-10-02 18:51:46 INFO  Executor:54 - Finished task 0.0 in stage 9.0 (TID 9). 2849 bytes result sent to driver
2019-10-02 18:51:46 INFO  TaskSetManager:54 - Finished task 0.0 in stage 9.0 (TID 9) in 206 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:46 INFO  TaskSchedulerImpl:54 - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2019-10-02 18:51:46 INFO  DAGScheduler:54 - ResultStage 9 (saveAsTable at Utils.scala:76) finished in 0.251 s
2019-10-02 18:51:46 INFO  DAGScheduler:54 - Job 6 finished: saveAsTable at Utils.scala:76, took 0.253629 s
2019-10-02 18:51:46 INFO  FileFormatWriter:54 - Job null committed.
2019-10-02 18:51:46 INFO  FileFormatWriter:54 - Finished processing stats for job null.
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:46 INFO  HiveExternalCatalog:54 - Persisting file based data source table `default`.`casualty_severity_code` into Hive metastore in Hive compatible format.
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: create_table: Table(tableName:casualty_severity_code, dbName:default, owner:user, createTime:1570038705, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/casualty_severity_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=create_table: Table(tableName:casualty_severity_code, dbName:default, owner:user, createTime:1570038705, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/casualty_severity_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:46 INFO  AlterTableRecoverPartitionsCommand:54 - Recover all the partitions in file:/C:/temp/casualty_severity_code
2019-10-02 18:51:46 INFO  AlterTableRecoverPartitionsCommand:54 - Found 1 partitions in file:/C:/temp/casualty_severity_code
2019-10-02 18:51:46 INFO  AlterTableRecoverPartitionsCommand:54 - Finished to gather the fast stats for all 1 partitions.
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: add_partitions
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=add_partitions	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=casualty_severity_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=casualty_severity_code	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: alter_table: db=default tbl=casualty_severity_code newtbl=casualty_severity_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=casualty_severity_code newtbl=casualty_severity_code	
2019-10-02 18:51:46 INFO  AlterTableRecoverPartitionsCommand:54 - Recovered all partitions (1).
2019-10-02 18:51:46 INFO  Utils$:77 - Utils.OverwriteTable(Casualty_Severity_Code)- Completed @ 2019-10-02T18:51:46.520
2019-10-02 18:51:46 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:46 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:46 INFO  FileSourceStrategy:54 - Output Data Schema: struct<>
2019-10-02 18:51:46 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:46 INFO  MemoryStore:54 - Block broadcast_17 stored as values in memory (estimated size 293.7 KB, free 1963.0 MB)
2019-10-02 18:51:46 INFO  MemoryStore:54 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1963.0 MB)
2019-10-02 18:51:46 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.0 MB)
2019-10-02 18:51:46 INFO  SparkContext:54 - Created broadcast 17 from count at ReferenceData.scala:42
2019-10-02 18:51:46 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:46 INFO  SparkContext:54 - Starting job: count at ReferenceData.scala:42
2019-10-02 18:51:46 INFO  DAGScheduler:54 - Registering RDD 40 (count at ReferenceData.scala:42)
2019-10-02 18:51:46 INFO  DAGScheduler:54 - Got job 7 (count at ReferenceData.scala:42) with 1 output partitions
2019-10-02 18:51:46 INFO  DAGScheduler:54 - Final stage: ResultStage 11 (count at ReferenceData.scala:42)
2019-10-02 18:51:46 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 10)
2019-10-02 18:51:46 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 10)
2019-10-02 18:51:46 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 10 (MapPartitionsRDD[40] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:46 INFO  MemoryStore:54 - Block broadcast_18 stored as values in memory (estimated size 14.4 KB, free 1962.9 MB)
2019-10-02 18:51:46 INFO  MemoryStore:54 - Block broadcast_18_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1962.9 MB)
2019-10-02 18:51:46 INFO  BlockManagerInfo:54 - Added broadcast_18_piece0 in memory on user-PC:62456 (size: 8.1 KB, free: 1965.0 MB)
2019-10-02 18:51:46 INFO  SparkContext:54 - Created broadcast 18 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:46 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[40] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:46 INFO  TaskSchedulerImpl:54 - Adding task set 10.0 with 1 tasks
2019-10-02 18:51:46 INFO  TaskSetManager:54 - Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8368 bytes)
2019-10-02 18:51:46 INFO  Executor:54 - Running task 0.0 in stage 10.0 (TID 10)
2019-10-02 18:51:46 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Casualty_Severity_Code.csv, range: 0-42, partition values: [empty row]
2019-10-02 18:51:46 INFO  Executor:54 - Finished task 0.0 in stage 10.0 (TID 10). 1540 bytes result sent to driver
2019-10-02 18:51:46 INFO  TaskSetManager:54 - Finished task 0.0 in stage 10.0 (TID 10) in 39 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:46 INFO  TaskSchedulerImpl:54 - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2019-10-02 18:51:46 INFO  DAGScheduler:54 - ShuffleMapStage 10 (count at ReferenceData.scala:42) finished in 0.049 s
2019-10-02 18:51:46 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-10-02 18:51:46 INFO  DAGScheduler:54 - running: Set()
2019-10-02 18:51:46 INFO  DAGScheduler:54 - waiting: Set(ResultStage 11)
2019-10-02 18:51:46 INFO  DAGScheduler:54 - failed: Set()
2019-10-02 18:51:46 INFO  DAGScheduler:54 - Submitting ResultStage 11 (MapPartitionsRDD[43] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:46 INFO  MemoryStore:54 - Block broadcast_19 stored as values in memory (estimated size 7.3 KB, free 1962.9 MB)
2019-10-02 18:51:46 INFO  MemoryStore:54 - Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1962.9 MB)
2019-10-02 18:51:46 INFO  BlockManagerInfo:54 - Added broadcast_19_piece0 in memory on user-PC:62456 (size: 3.8 KB, free: 1965.0 MB)
2019-10-02 18:51:46 INFO  SparkContext:54 - Created broadcast 19 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:46 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[43] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:46 INFO  TaskSchedulerImpl:54 - Adding task set 11.0 with 1 tasks
2019-10-02 18:51:46 INFO  TaskSetManager:54 - Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, ANY, 7754 bytes)
2019-10-02 18:51:46 INFO  Executor:54 - Running task 0.0 in stage 11.0 (TID 11)
2019-10-02 18:51:46 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2019-10-02 18:51:46 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2019-10-02 18:51:46 INFO  Executor:54 - Finished task 0.0 in stage 11.0 (TID 11). 1739 bytes result sent to driver
2019-10-02 18:51:46 INFO  TaskSetManager:54 - Finished task 0.0 in stage 11.0 (TID 11) in 13 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:46 INFO  TaskSchedulerImpl:54 - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2019-10-02 18:51:46 INFO  DAGScheduler:54 - ResultStage 11 (count at ReferenceData.scala:42) finished in 0.038 s
2019-10-02 18:51:46 INFO  DAGScheduler:54 - Job 7 finished: count at ReferenceData.scala:42, took 0.093331 s
---------------------------------------------------------------------------------------------------------
The Reference Table :Casualty_Severity_Code : Loaded into HIVE with counts of 3
---------------------------------------------------------------------------------------------------------
2019-10-02 18:51:46 INFO  Utils$:51 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\First_Road_Class_Code.csv)- Started @ 2019-10-02T18:51:46.743
2019-10-02 18:51:46 INFO  Utils$:58 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\First_Road_Class_Code.csv)- Completed @ 2019-10-02T18:51:46.759
2019-10-02 18:51:46 INFO  Utils$:67 - Utils.OverwriteTable(First_Road_Class_Code)- Started @ 2019-10-02T18:51:46.796
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:46 INFO  HiveMetaStore:746 - 0: drop_table : db=default tbl=first_road_class_code
2019-10-02 18:51:46 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:47 INFO  hivemetastoressimpl:41 - deleting  file:/C:/temp/first_road_class_code
2019-10-02 18:51:47 INFO  TrashPolicyDefault:92 - Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2019-10-02 18:51:47 INFO  hivemetastoressimpl:53 - Deleted the diretory file:/C:/temp/first_road_class_code
2019-10-02 18:51:47 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:47 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:47 INFO  FileSourceStrategy:54 - Output Data Schema: struct<Type_Code: smallint, Type: string>
2019-10-02 18:51:47 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:47 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:47 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:47 INFO  MemoryStore:54 - Block broadcast_20 stored as values in memory (estimated size 293.7 KB, free 1962.6 MB)
2019-10-02 18:51:47 INFO  MemoryStore:54 - Block broadcast_20_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1962.6 MB)
2019-10-02 18:51:47 INFO  BlockManagerInfo:54 - Added broadcast_20_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.0 MB)
2019-10-02 18:51:47 INFO  SparkContext:54 - Created broadcast 20 from saveAsTable at Utils.scala:76
2019-10-02 18:51:47 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:47 INFO  SparkContext:54 - Starting job: saveAsTable at Utils.scala:76
2019-10-02 18:51:47 INFO  DAGScheduler:54 - Got job 8 (saveAsTable at Utils.scala:76) with 1 output partitions
2019-10-02 18:51:47 INFO  DAGScheduler:54 - Final stage: ResultStage 12 (saveAsTable at Utils.scala:76)
2019-10-02 18:51:47 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-10-02 18:51:47 INFO  DAGScheduler:54 - Missing parents: List()
2019-10-02 18:51:47 INFO  DAGScheduler:54 - Submitting ResultStage 12 (MapPartitionsRDD[46] at saveAsTable at Utils.scala:76), which has no missing parents
2019-10-02 18:51:47 INFO  MemoryStore:54 - Block broadcast_21 stored as values in memory (estimated size 158.1 KB, free 1962.5 MB)
2019-10-02 18:51:47 INFO  MemoryStore:54 - Block broadcast_21_piece0 stored as bytes in memory (estimated size 58.2 KB, free 1962.4 MB)
2019-10-02 18:51:47 INFO  BlockManagerInfo:54 - Added broadcast_21_piece0 in memory on user-PC:62456 (size: 58.2 KB, free: 1964.9 MB)
2019-10-02 18:51:47 INFO  SparkContext:54 - Created broadcast 21 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:47 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[46] at saveAsTable at Utils.scala:76) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:47 INFO  TaskSchedulerImpl:54 - Adding task set 12.0 with 1 tasks
2019-10-02 18:51:47 INFO  TaskSetManager:54 - Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 8378 bytes)
2019-10-02 18:51:47 INFO  Executor:54 - Running task 0.0 in stage 12.0 (TID 12)
2019-10-02 18:51:47 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/First_Road_Class_Code.csv, range: 0-63, partition values: [empty row]
2019-10-02 18:51:47 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:47 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:47 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20191002185147_0012_m_000000_0' to file:/C:/temp/first_road_class_code/_temporary/0/task_20191002185147_0012_m_000000
2019-10-02 18:51:47 INFO  SparkHadoopMapRedUtil:54 - attempt_20191002185147_0012_m_000000_0: Committed
2019-10-02 18:51:47 INFO  Executor:54 - Finished task 0.0 in stage 12.0 (TID 12). 2849 bytes result sent to driver
2019-10-02 18:51:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 12.0 (TID 12) in 170 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:47 INFO  TaskSchedulerImpl:54 - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2019-10-02 18:51:47 INFO  DAGScheduler:54 - ResultStage 12 (saveAsTable at Utils.scala:76) finished in 0.221 s
2019-10-02 18:51:47 INFO  DAGScheduler:54 - Job 8 finished: saveAsTable at Utils.scala:76, took 0.228447 s
2019-10-02 18:51:47 INFO  FileFormatWriter:54 - Job null committed.
2019-10-02 18:51:47 INFO  FileFormatWriter:54 - Finished processing stats for job null.
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:47 INFO  HiveExternalCatalog:54 - Persisting file based data source table `default`.`first_road_class_code` into Hive metastore in Hive compatible format.
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: create_table: Table(tableName:first_road_class_code, dbName:default, owner:user, createTime:1570038707, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/first_road_class_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=create_table: Table(tableName:first_road_class_code, dbName:default, owner:user, createTime:1570038707, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/first_road_class_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:47 INFO  AlterTableRecoverPartitionsCommand:54 - Recover all the partitions in file:/C:/temp/first_road_class_code
2019-10-02 18:51:47 INFO  AlterTableRecoverPartitionsCommand:54 - Found 1 partitions in file:/C:/temp/first_road_class_code
2019-10-02 18:51:47 INFO  AlterTableRecoverPartitionsCommand:54 - Finished to gather the fast stats for all 1 partitions.
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: add_partitions
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=add_partitions	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=first_road_class_code
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=first_road_class_code	
2019-10-02 18:51:47 INFO  HiveMetaStore:746 - 0: alter_table: db=default tbl=first_road_class_code newtbl=first_road_class_code
2019-10-02 18:51:47 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=first_road_class_code newtbl=first_road_class_code	
2019-10-02 18:51:47 INFO  AlterTableRecoverPartitionsCommand:54 - Recovered all partitions (1).
2019-10-02 18:51:47 INFO  Utils$:77 - Utils.OverwriteTable(First_Road_Class_Code)- Completed @ 2019-10-02T18:51:47.868
2019-10-02 18:51:47 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:47 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:47 INFO  FileSourceStrategy:54 - Output Data Schema: struct<>
2019-10-02 18:51:47 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:47 INFO  MemoryStore:54 - Block broadcast_22 stored as values in memory (estimated size 293.7 KB, free 1962.1 MB)
2019-10-02 18:51:47 INFO  MemoryStore:54 - Block broadcast_22_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1962.1 MB)
2019-10-02 18:51:47 INFO  BlockManagerInfo:54 - Added broadcast_22_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1964.9 MB)
2019-10-02 18:51:47 INFO  SparkContext:54 - Created broadcast 22 from count at ReferenceData.scala:42
2019-10-02 18:51:47 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:47 INFO  SparkContext:54 - Starting job: count at ReferenceData.scala:42
2019-10-02 18:51:48 INFO  DAGScheduler:54 - Registering RDD 51 (count at ReferenceData.scala:42)
2019-10-02 18:51:48 INFO  DAGScheduler:54 - Got job 9 (count at ReferenceData.scala:42) with 1 output partitions
2019-10-02 18:51:48 INFO  DAGScheduler:54 - Final stage: ResultStage 14 (count at ReferenceData.scala:42)
2019-10-02 18:51:48 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 13)
2019-10-02 18:51:48 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 13)
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 203
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 256
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 306
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 347
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 153
2019-10-02 18:51:48 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 13 (MapPartitionsRDD[51] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 424
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 315
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 383
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 398
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 335
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 220
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 355
2019-10-02 18:51:48 INFO  MemoryStore:54 - Block broadcast_23 stored as values in memory (estimated size 14.4 KB, free 1962.1 MB)
2019-10-02 18:51:48 INFO  MemoryStore:54 - Block broadcast_23_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1962.1 MB)
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 196
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 294
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 365
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 439
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 179
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 155
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 362
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 453
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 269
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 210
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 199
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 352
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 409
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 226
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 356
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Added broadcast_23_piece0 in memory on user-PC:62456 (size: 8.1 KB, free: 1964.9 MB)
2019-10-02 18:51:48 INFO  SparkContext:54 - Created broadcast 23 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:48 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[51] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:48 INFO  TaskSchedulerImpl:54 - Adding task set 13.0 with 1 tasks
2019-10-02 18:51:48 INFO  TaskSetManager:54 - Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 8367 bytes)
2019-10-02 18:51:48 INFO  Executor:54 - Running task 0.0 in stage 13.0 (TID 13)
2019-10-02 18:51:48 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/First_Road_Class_Code.csv, range: 0-63, partition values: [empty row]
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Removed broadcast_20_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1964.9 MB)
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 249
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 412
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 291
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 321
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 224
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 466
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 272
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 414
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 248
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 350
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 279
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 215
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 320
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 393
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 461
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 275
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 151
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 193
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 274
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 395
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 336
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 363
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 232
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 247
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 369
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 451
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 189
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 198
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 283
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 258
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 154
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 341
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Removed broadcast_16_piece0 on user-PC:62456 in memory (size: 58.2 KB, free: 1965.0 MB)
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 172
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 169
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 300
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 236
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 313
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 467
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on user-PC:62456 in memory (size: 3.8 KB, free: 1965.0 MB)
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 379
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 457
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 459
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 311
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 402
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 302
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 261
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 262
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 295
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 171
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 268
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 287
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 429
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 374
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 394
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 354
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 441
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 449
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 152
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 440
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 185
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 296
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 212
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 165
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 253
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 243
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 381
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 410
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 221
2019-10-02 18:51:48 INFO  Executor:54 - Finished task 0.0 in stage 13.0 (TID 13). 1540 bytes result sent to driver
2019-10-02 18:51:48 INFO  TaskSetManager:54 - Finished task 0.0 in stage 13.0 (TID 13) in 92 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:48 INFO  TaskSchedulerImpl:54 - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2019-10-02 18:51:48 INFO  DAGScheduler:54 - ShuffleMapStage 13 (count at ReferenceData.scala:42) finished in 0.133 s
2019-10-02 18:51:48 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-10-02 18:51:48 INFO  DAGScheduler:54 - running: Set()
2019-10-02 18:51:48 INFO  DAGScheduler:54 - waiting: Set(ResultStage 14)
2019-10-02 18:51:48 INFO  DAGScheduler:54 - failed: Set()
2019-10-02 18:51:48 INFO  DAGScheduler:54 - Submitting ResultStage 14 (MapPartitionsRDD[54] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:48 INFO  MemoryStore:54 - Block broadcast_24 stored as values in memory (estimated size 7.3 KB, free 1962.6 MB)
2019-10-02 18:51:48 INFO  MemoryStore:54 - Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1962.6 MB)
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Removed broadcast_13_piece0 on user-PC:62456 in memory (size: 8.1 KB, free: 1965.0 MB)
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Added broadcast_24_piece0 in memory on user-PC:62456 (size: 3.8 KB, free: 1965.0 MB)
2019-10-02 18:51:48 INFO  SparkContext:54 - Created broadcast 24 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:48 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[54] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:48 INFO  TaskSchedulerImpl:54 - Adding task set 14.0 with 1 tasks
2019-10-02 18:51:48 INFO  TaskSetManager:54 - Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, ANY, 7754 bytes)
2019-10-02 18:51:48 INFO  Executor:54 - Running task 0.0 in stage 14.0 (TID 14)
2019-10-02 18:51:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2019-10-02 18:51:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-10-02 18:51:48 INFO  Executor:54 - Finished task 0.0 in stage 14.0 (TID 14). 1696 bytes result sent to driver
2019-10-02 18:51:48 INFO  TaskSetManager:54 - Finished task 0.0 in stage 14.0 (TID 14) in 11 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:48 INFO  DAGScheduler:54 - ResultStage 14 (count at ReferenceData.scala:42) finished in 0.039 s
2019-10-02 18:51:48 INFO  TaskSchedulerImpl:54 - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 391
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 257
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 330
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 447
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 397
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 470
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 293
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 308
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 367
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 209
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 285
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 167
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 312
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 436
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 191
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 376
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 325
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 331
2019-10-02 18:51:48 INFO  DAGScheduler:54 - Job 9 finished: count at ReferenceData.scala:42, took 0.186931 s
---------------------------------------------------------------------------------------------------------
The Reference Table :First_Road_Class_Code : Loaded into HIVE with counts of 6
---------------------------------------------------------------------------------------------------------
2019-10-02 18:51:48 INFO  Utils$:51 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Local_Authority_District_Code.csv)- Started @ 2019-10-02T18:51:48.192
2019-10-02 18:51:48 INFO  Utils$:58 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Local_Authority_District_Code.csv)- Completed @ 2019-10-02T18:51:48.201
2019-10-02 18:51:48 INFO  Utils$:67 - Utils.OverwriteTable(Local_Authority_District_Code)- Started @ 2019-10-02T18:51:48.241
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 290
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 317
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 370
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 213
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 237
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 473
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 314
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 389
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 380
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 396
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 277
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 401
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 188
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 251
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 282
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 304
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 430
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 267
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 388
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 176
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 338
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 445
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 392
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 460
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 252
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 305
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 353
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 310
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 246
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 259
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 166
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 422
2019-10-02 18:51:48 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:48 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 234
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 299
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 192
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 208
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 178
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 231
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 244
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned shuffle 3
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 348
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 200
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 265
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 288
2019-10-02 18:51:48 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:48 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Removed broadcast_19_piece0 on user-PC:62456 in memory (size: 3.8 KB, free: 1965.0 MB)
2019-10-02 18:51:48 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:48 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 399
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 164
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 318
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 284
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 343
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 465
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 175
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 228
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 360
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 273
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 407
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 205
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 416
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 455
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 448
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 361
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 219
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 469
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 405
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 206
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 322
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 382
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 157
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 332
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 233
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 418
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 303
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 357
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 301
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 278
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 242
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 271
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 452
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 266
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 222
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 297
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 162
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 240
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 207
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 433
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 456
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 386
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 177
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 359
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 471
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 413
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 387
2019-10-02 18:51:48 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:48 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned shuffle 2
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 437
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 238
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 366
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 229
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 270
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 462
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 173
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 184
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 255
2019-10-02 18:51:48 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:48 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:48 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:48 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:48 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:48 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:48 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:48 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:48 INFO  HiveMetaStore:746 - 0: drop_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:48 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Removed broadcast_15_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1965.0 MB)
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 458
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 364
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 289
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned shuffle 1
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 432
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 435
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 477
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 400
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 334
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 419
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 443
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 372
2019-10-02 18:51:48 INFO  hivemetastoressimpl:41 - deleting  file:/C:/temp/local_authority_district_code
2019-10-02 18:51:48 INFO  TrashPolicyDefault:92 - Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2019-10-02 18:51:48 INFO  hivemetastoressimpl:53 - Deleted the diretory file:/C:/temp/local_authority_district_code
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Removed broadcast_14_piece0 on user-PC:62456 in memory (size: 3.8 KB, free: 1965.0 MB)
2019-10-02 18:51:48 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:48 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:48 INFO  FileSourceStrategy:54 - Output Data Schema: struct<Type_Code: smallint, Type: string>
2019-10-02 18:51:48 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:48 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:48 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:48 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:48 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:48 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:48 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:48 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:48 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 329
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 159
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 450
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 344
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 434
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 160
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1965.0 MB)
2019-10-02 18:51:48 INFO  MemoryStore:54 - Block broadcast_25 stored as values in memory (estimated size 293.7 KB, free 1963.0 MB)
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 442
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 420
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 368
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 438
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 371
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 377
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 309
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Removed broadcast_17_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1965.1 MB)
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 186
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 292
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 218
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 474
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 472
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 182
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 358
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 174
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 326
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 327
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 421
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 351
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 263
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 323
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 241
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 187
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 235
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 260
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 385
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 170
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 307
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 197
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 264
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 161
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 375
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 404
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 342
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 163
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 476
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 276
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 316
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 250
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 227
2019-10-02 18:51:48 INFO  MemoryStore:54 - Block broadcast_25_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1963.2 MB)
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Added broadcast_25_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.0 MB)
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Removed broadcast_18_piece0 on user-PC:62456 in memory (size: 8.1 KB, free: 1965.0 MB)
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 468
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 475
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 337
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 425
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 340
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 216
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 204
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 345
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 180
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 427
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 181
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 214
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 286
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 408
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 463
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 223
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 378
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 339
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 411
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 239
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 217
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 158
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 225
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 428
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 423
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 444
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 349
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 390
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 431
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 417
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 168
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 183
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 202
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 333
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on user-PC:62456 in memory (size: 58.2 KB, free: 1965.1 MB)
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 415
2019-10-02 18:51:48 INFO  SparkContext:54 - Created broadcast 25 from saveAsTable at Utils.scala:76
2019-10-02 18:51:48 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Removed broadcast_21_piece0 on user-PC:62456 in memory (size: 58.2 KB, free: 1965.2 MB)
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 373
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 195
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 426
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 346
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 464
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 403
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 281
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 156
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 446
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 298
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 328
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on user-PC:62456 in memory (size: 8.1 KB, free: 1965.2 MB)
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 245
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 230
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1965.2 MB)
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 201
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 384
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 454
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 406
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Removed broadcast_12_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1965.2 MB)
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 190
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 319
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 280
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 194
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 211
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 324
2019-10-02 18:51:48 INFO  ContextCleaner:54 - Cleaned accumulator 254
2019-10-02 18:51:48 INFO  SparkContext:54 - Starting job: saveAsTable at Utils.scala:76
2019-10-02 18:51:48 INFO  DAGScheduler:54 - Got job 10 (saveAsTable at Utils.scala:76) with 1 output partitions
2019-10-02 18:51:48 INFO  DAGScheduler:54 - Final stage: ResultStage 15 (saveAsTable at Utils.scala:76)
2019-10-02 18:51:48 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-10-02 18:51:48 INFO  DAGScheduler:54 - Missing parents: List()
2019-10-02 18:51:48 INFO  DAGScheduler:54 - Submitting ResultStage 15 (MapPartitionsRDD[57] at saveAsTable at Utils.scala:76), which has no missing parents
2019-10-02 18:51:48 INFO  MemoryStore:54 - Block broadcast_26 stored as values in memory (estimated size 158.2 KB, free 1964.2 MB)
2019-10-02 18:51:48 INFO  MemoryStore:54 - Block broadcast_26_piece0 stored as bytes in memory (estimated size 58.2 KB, free 1964.1 MB)
2019-10-02 18:51:48 INFO  BlockManagerInfo:54 - Added broadcast_26_piece0 in memory on user-PC:62456 (size: 58.2 KB, free: 1965.2 MB)
2019-10-02 18:51:48 INFO  SparkContext:54 - Created broadcast 26 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:48 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[57] at saveAsTable at Utils.scala:76) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:48 INFO  TaskSchedulerImpl:54 - Adding task set 15.0 with 1 tasks
2019-10-02 18:51:48 INFO  TaskSetManager:54 - Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8386 bytes)
2019-10-02 18:51:48 INFO  Executor:54 - Running task 0.0 in stage 15.0 (TID 15)
2019-10-02 18:51:48 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Local_Authority_District_Code.csv, range: 0-7062, partition values: [empty row]
2019-10-02 18:51:48 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:48 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:48 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20191002185148_0015_m_000000_0' to file:/C:/temp/local_authority_district_code/_temporary/0/task_20191002185148_0015_m_000000
2019-10-02 18:51:48 INFO  SparkHadoopMapRedUtil:54 - attempt_20191002185148_0015_m_000000_0: Committed
2019-10-02 18:51:49 INFO  Executor:54 - Finished task 0.0 in stage 15.0 (TID 15). 2849 bytes result sent to driver
2019-10-02 18:51:49 INFO  TaskSetManager:54 - Finished task 0.0 in stage 15.0 (TID 15) in 254 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:49 INFO  DAGScheduler:54 - ResultStage 15 (saveAsTable at Utils.scala:76) finished in 0.297 s
2019-10-02 18:51:49 INFO  TaskSchedulerImpl:54 - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2019-10-02 18:51:49 INFO  DAGScheduler:54 - Job 10 finished: saveAsTable at Utils.scala:76, took 0.300529 s
2019-10-02 18:51:49 INFO  FileFormatWriter:54 - Job null committed.
2019-10-02 18:51:49 INFO  FileFormatWriter:54 - Finished processing stats for job null.
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:49 INFO  HiveExternalCatalog:54 - Persisting file based data source table `default`.`local_authority_district_code` into Hive metastore in Hive compatible format.
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: create_table: Table(tableName:local_authority_district_code, dbName:default, owner:user, createTime:1570038708, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/local_authority_district_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=create_table: Table(tableName:local_authority_district_code, dbName:default, owner:user, createTime:1570038708, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/local_authority_district_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:49 INFO  AlterTableRecoverPartitionsCommand:54 - Recover all the partitions in file:/C:/temp/local_authority_district_code
2019-10-02 18:51:49 INFO  AlterTableRecoverPartitionsCommand:54 - Found 1 partitions in file:/C:/temp/local_authority_district_code
2019-10-02 18:51:49 INFO  AlterTableRecoverPartitionsCommand:54 - Finished to gather the fast stats for all 1 partitions.
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: add_partitions
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=add_partitions	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=local_authority_district_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=local_authority_district_code	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: alter_table: db=default tbl=local_authority_district_code newtbl=local_authority_district_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=local_authority_district_code newtbl=local_authority_district_code	
2019-10-02 18:51:49 INFO  AlterTableRecoverPartitionsCommand:54 - Recovered all partitions (1).
2019-10-02 18:51:49 INFO  Utils$:77 - Utils.OverwriteTable(Local_Authority_District_Code)- Completed @ 2019-10-02T18:51:49.676
2019-10-02 18:51:49 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:49 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:49 INFO  FileSourceStrategy:54 - Output Data Schema: struct<>
2019-10-02 18:51:49 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:49 INFO  MemoryStore:54 - Block broadcast_27 stored as values in memory (estimated size 293.7 KB, free 1963.8 MB)
2019-10-02 18:51:49 INFO  MemoryStore:54 - Block broadcast_27_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1963.8 MB)
2019-10-02 18:51:49 INFO  BlockManagerInfo:54 - Added broadcast_27_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.1 MB)
2019-10-02 18:51:49 INFO  SparkContext:54 - Created broadcast 27 from count at ReferenceData.scala:42
2019-10-02 18:51:49 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:49 INFO  SparkContext:54 - Starting job: count at ReferenceData.scala:42
2019-10-02 18:51:49 INFO  DAGScheduler:54 - Registering RDD 62 (count at ReferenceData.scala:42)
2019-10-02 18:51:49 INFO  DAGScheduler:54 - Got job 11 (count at ReferenceData.scala:42) with 1 output partitions
2019-10-02 18:51:49 INFO  DAGScheduler:54 - Final stage: ResultStage 17 (count at ReferenceData.scala:42)
2019-10-02 18:51:49 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 16)
2019-10-02 18:51:49 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 16)
2019-10-02 18:51:49 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 16 (MapPartitionsRDD[62] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:49 INFO  MemoryStore:54 - Block broadcast_28 stored as values in memory (estimated size 14.4 KB, free 1963.8 MB)
2019-10-02 18:51:49 INFO  MemoryStore:54 - Block broadcast_28_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1963.8 MB)
2019-10-02 18:51:49 INFO  BlockManagerInfo:54 - Added broadcast_28_piece0 in memory on user-PC:62456 (size: 8.1 KB, free: 1965.1 MB)
2019-10-02 18:51:49 INFO  SparkContext:54 - Created broadcast 28 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:49 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[62] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:49 INFO  TaskSchedulerImpl:54 - Adding task set 16.0 with 1 tasks
2019-10-02 18:51:49 INFO  TaskSetManager:54 - Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 8375 bytes)
2019-10-02 18:51:49 INFO  Executor:54 - Running task 0.0 in stage 16.0 (TID 16)
2019-10-02 18:51:49 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Local_Authority_District_Code.csv, range: 0-7062, partition values: [empty row]
2019-10-02 18:51:49 INFO  Executor:54 - Finished task 0.0 in stage 16.0 (TID 16). 1540 bytes result sent to driver
2019-10-02 18:51:49 INFO  TaskSetManager:54 - Finished task 0.0 in stage 16.0 (TID 16) in 50 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:49 INFO  TaskSchedulerImpl:54 - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2019-10-02 18:51:49 INFO  DAGScheduler:54 - ShuffleMapStage 16 (count at ReferenceData.scala:42) finished in 0.058 s
2019-10-02 18:51:49 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-10-02 18:51:49 INFO  DAGScheduler:54 - running: Set()
2019-10-02 18:51:49 INFO  DAGScheduler:54 - waiting: Set(ResultStage 17)
2019-10-02 18:51:49 INFO  DAGScheduler:54 - failed: Set()
2019-10-02 18:51:49 INFO  DAGScheduler:54 - Submitting ResultStage 17 (MapPartitionsRDD[65] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:49 INFO  MemoryStore:54 - Block broadcast_29 stored as values in memory (estimated size 7.3 KB, free 1963.8 MB)
2019-10-02 18:51:49 INFO  MemoryStore:54 - Block broadcast_29_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1963.8 MB)
2019-10-02 18:51:49 INFO  BlockManagerInfo:54 - Added broadcast_29_piece0 in memory on user-PC:62456 (size: 3.8 KB, free: 1965.1 MB)
2019-10-02 18:51:49 INFO  SparkContext:54 - Created broadcast 29 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:49 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[65] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:49 INFO  TaskSchedulerImpl:54 - Adding task set 17.0 with 1 tasks
2019-10-02 18:51:49 INFO  TaskSetManager:54 - Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, ANY, 7754 bytes)
2019-10-02 18:51:49 INFO  Executor:54 - Running task 0.0 in stage 17.0 (TID 17)
2019-10-02 18:51:49 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2019-10-02 18:51:49 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-10-02 18:51:49 INFO  Executor:54 - Finished task 0.0 in stage 17.0 (TID 17). 1696 bytes result sent to driver
2019-10-02 18:51:49 INFO  TaskSetManager:54 - Finished task 0.0 in stage 17.0 (TID 17) in 8 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:49 INFO  TaskSchedulerImpl:54 - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2019-10-02 18:51:49 INFO  DAGScheduler:54 - ResultStage 17 (count at ReferenceData.scala:42) finished in 0.015 s
2019-10-02 18:51:49 INFO  DAGScheduler:54 - Job 11 finished: count at ReferenceData.scala:42, took 0.081258 s
---------------------------------------------------------------------------------------------------------
The Reference Table :Local_Authority_District_Code : Loaded into HIVE with counts of 416
---------------------------------------------------------------------------------------------------------
2019-10-02 18:51:49 INFO  Utils$:51 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Road_Surface_Conditions_Code.csv)- Started @ 2019-10-02T18:51:49.861
2019-10-02 18:51:49 INFO  Utils$:58 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Road_Surface_Conditions_Code.csv)- Completed @ 2019-10-02T18:51:49.875
2019-10-02 18:51:49 INFO  Utils$:67 - Utils.OverwriteTable(Road_Surface_Conditions_Code)- Started @ 2019-10-02T18:51:49.904
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:49 INFO  HiveMetaStore:746 - 0: drop_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:49 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:50 INFO  hivemetastoressimpl:41 - deleting  file:/C:/temp/road_surface_conditions_code
2019-10-02 18:51:50 INFO  TrashPolicyDefault:92 - Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2019-10-02 18:51:50 INFO  hivemetastoressimpl:53 - Deleted the diretory file:/C:/temp/road_surface_conditions_code
2019-10-02 18:51:50 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:50 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:50 INFO  FileSourceStrategy:54 - Output Data Schema: struct<Type_Code: smallint, Type: string>
2019-10-02 18:51:50 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:50 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:50 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:50 INFO  MemoryStore:54 - Block broadcast_30 stored as values in memory (estimated size 293.7 KB, free 1963.5 MB)
2019-10-02 18:51:50 INFO  MemoryStore:54 - Block broadcast_30_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1963.5 MB)
2019-10-02 18:51:50 INFO  BlockManagerInfo:54 - Added broadcast_30_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.1 MB)
2019-10-02 18:51:50 INFO  SparkContext:54 - Created broadcast 30 from saveAsTable at Utils.scala:76
2019-10-02 18:51:50 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:50 INFO  SparkContext:54 - Starting job: saveAsTable at Utils.scala:76
2019-10-02 18:51:50 INFO  DAGScheduler:54 - Got job 12 (saveAsTable at Utils.scala:76) with 1 output partitions
2019-10-02 18:51:50 INFO  DAGScheduler:54 - Final stage: ResultStage 18 (saveAsTable at Utils.scala:76)
2019-10-02 18:51:50 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-10-02 18:51:50 INFO  DAGScheduler:54 - Missing parents: List()
2019-10-02 18:51:50 INFO  DAGScheduler:54 - Submitting ResultStage 18 (MapPartitionsRDD[68] at saveAsTable at Utils.scala:76), which has no missing parents
2019-10-02 18:51:50 INFO  MemoryStore:54 - Block broadcast_31 stored as values in memory (estimated size 158.2 KB, free 1963.3 MB)
2019-10-02 18:51:50 INFO  MemoryStore:54 - Block broadcast_31_piece0 stored as bytes in memory (estimated size 58.2 KB, free 1963.3 MB)
2019-10-02 18:51:50 INFO  BlockManagerInfo:54 - Added broadcast_31_piece0 in memory on user-PC:62456 (size: 58.2 KB, free: 1965.0 MB)
2019-10-02 18:51:50 INFO  SparkContext:54 - Created broadcast 31 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:50 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[68] at saveAsTable at Utils.scala:76) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:50 INFO  TaskSchedulerImpl:54 - Adding task set 18.0 with 1 tasks
2019-10-02 18:51:50 INFO  TaskSetManager:54 - Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 8385 bytes)
2019-10-02 18:51:50 INFO  Executor:54 - Running task 0.0 in stage 18.0 (TID 18)
2019-10-02 18:51:50 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Road_Surface_Conditions_Code.csv, range: 0-139, partition values: [empty row]
2019-10-02 18:51:50 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:50 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:50 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20191002185150_0018_m_000000_0' to file:/C:/temp/road_surface_conditions_code/_temporary/0/task_20191002185150_0018_m_000000
2019-10-02 18:51:50 INFO  SparkHadoopMapRedUtil:54 - attempt_20191002185150_0018_m_000000_0: Committed
2019-10-02 18:51:50 INFO  Executor:54 - Finished task 0.0 in stage 18.0 (TID 18). 2849 bytes result sent to driver
2019-10-02 18:51:50 INFO  TaskSetManager:54 - Finished task 0.0 in stage 18.0 (TID 18) in 137 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:50 INFO  TaskSchedulerImpl:54 - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2019-10-02 18:51:50 INFO  DAGScheduler:54 - ResultStage 18 (saveAsTable at Utils.scala:76) finished in 0.183 s
2019-10-02 18:51:50 INFO  DAGScheduler:54 - Job 12 finished: saveAsTable at Utils.scala:76, took 0.185340 s
2019-10-02 18:51:50 INFO  FileFormatWriter:54 - Job null committed.
2019-10-02 18:51:50 INFO  FileFormatWriter:54 - Finished processing stats for job null.
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:50 INFO  HiveExternalCatalog:54 - Persisting file based data source table `default`.`road_surface_conditions_code` into Hive metastore in Hive compatible format.
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: create_table: Table(tableName:road_surface_conditions_code, dbName:default, owner:user, createTime:1570038710, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/road_surface_conditions_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=create_table: Table(tableName:road_surface_conditions_code, dbName:default, owner:user, createTime:1570038710, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/road_surface_conditions_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:50 INFO  AlterTableRecoverPartitionsCommand:54 - Recover all the partitions in file:/C:/temp/road_surface_conditions_code
2019-10-02 18:51:50 INFO  AlterTableRecoverPartitionsCommand:54 - Found 1 partitions in file:/C:/temp/road_surface_conditions_code
2019-10-02 18:51:50 INFO  AlterTableRecoverPartitionsCommand:54 - Finished to gather the fast stats for all 1 partitions.
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: add_partitions
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=add_partitions	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_surface_conditions_code
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_surface_conditions_code	
2019-10-02 18:51:50 INFO  HiveMetaStore:746 - 0: alter_table: db=default tbl=road_surface_conditions_code newtbl=road_surface_conditions_code
2019-10-02 18:51:50 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=road_surface_conditions_code newtbl=road_surface_conditions_code	
2019-10-02 18:51:50 INFO  AlterTableRecoverPartitionsCommand:54 - Recovered all partitions (1).
2019-10-02 18:51:50 INFO  Utils$:77 - Utils.OverwriteTable(Road_Surface_Conditions_Code)- Completed @ 2019-10-02T18:51:50.839
2019-10-02 18:51:50 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:50 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:50 INFO  FileSourceStrategy:54 - Output Data Schema: struct<>
2019-10-02 18:51:50 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:50 INFO  MemoryStore:54 - Block broadcast_32 stored as values in memory (estimated size 293.7 KB, free 1963.0 MB)
2019-10-02 18:51:50 INFO  MemoryStore:54 - Block broadcast_32_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1963.0 MB)
2019-10-02 18:51:50 INFO  BlockManagerInfo:54 - Added broadcast_32_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.0 MB)
2019-10-02 18:51:50 INFO  SparkContext:54 - Created broadcast 32 from count at ReferenceData.scala:42
2019-10-02 18:51:50 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:50 INFO  SparkContext:54 - Starting job: count at ReferenceData.scala:42
2019-10-02 18:51:50 INFO  DAGScheduler:54 - Registering RDD 73 (count at ReferenceData.scala:42)
2019-10-02 18:51:50 INFO  DAGScheduler:54 - Got job 13 (count at ReferenceData.scala:42) with 1 output partitions
2019-10-02 18:51:50 INFO  DAGScheduler:54 - Final stage: ResultStage 20 (count at ReferenceData.scala:42)
2019-10-02 18:51:50 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 19)
2019-10-02 18:51:50 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 19)
2019-10-02 18:51:50 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 19 (MapPartitionsRDD[73] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:50 INFO  MemoryStore:54 - Block broadcast_33 stored as values in memory (estimated size 14.4 KB, free 1962.9 MB)
2019-10-02 18:51:50 INFO  MemoryStore:54 - Block broadcast_33_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1962.9 MB)
2019-10-02 18:51:50 INFO  BlockManagerInfo:54 - Added broadcast_33_piece0 in memory on user-PC:62456 (size: 8.1 KB, free: 1965.0 MB)
2019-10-02 18:51:50 INFO  SparkContext:54 - Created broadcast 33 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:50 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[73] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:50 INFO  TaskSchedulerImpl:54 - Adding task set 19.0 with 1 tasks
2019-10-02 18:51:50 INFO  TaskSetManager:54 - Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 8374 bytes)
2019-10-02 18:51:50 INFO  Executor:54 - Running task 0.0 in stage 19.0 (TID 19)
2019-10-02 18:51:50 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Road_Surface_Conditions_Code.csv, range: 0-139, partition values: [empty row]
2019-10-02 18:51:50 INFO  Executor:54 - Finished task 0.0 in stage 19.0 (TID 19). 1540 bytes result sent to driver
2019-10-02 18:51:50 INFO  TaskSetManager:54 - Finished task 0.0 in stage 19.0 (TID 19) in 45 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:50 INFO  TaskSchedulerImpl:54 - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2019-10-02 18:51:50 INFO  DAGScheduler:54 - ShuffleMapStage 19 (count at ReferenceData.scala:42) finished in 0.056 s
2019-10-02 18:51:50 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-10-02 18:51:50 INFO  DAGScheduler:54 - running: Set()
2019-10-02 18:51:50 INFO  DAGScheduler:54 - waiting: Set(ResultStage 20)
2019-10-02 18:51:50 INFO  DAGScheduler:54 - failed: Set()
2019-10-02 18:51:50 INFO  DAGScheduler:54 - Submitting ResultStage 20 (MapPartitionsRDD[76] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:50 INFO  MemoryStore:54 - Block broadcast_34 stored as values in memory (estimated size 7.3 KB, free 1962.9 MB)
2019-10-02 18:51:50 INFO  MemoryStore:54 - Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1962.9 MB)
2019-10-02 18:51:50 INFO  BlockManagerInfo:54 - Added broadcast_34_piece0 in memory on user-PC:62456 (size: 3.8 KB, free: 1965.0 MB)
2019-10-02 18:51:50 INFO  SparkContext:54 - Created broadcast 34 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:50 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[76] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:50 INFO  TaskSchedulerImpl:54 - Adding task set 20.0 with 1 tasks
2019-10-02 18:51:50 INFO  TaskSetManager:54 - Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, ANY, 7754 bytes)
2019-10-02 18:51:50 INFO  Executor:54 - Running task 0.0 in stage 20.0 (TID 20)
2019-10-02 18:51:50 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2019-10-02 18:51:50 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-10-02 18:51:50 INFO  Executor:54 - Finished task 0.0 in stage 20.0 (TID 20). 1739 bytes result sent to driver
2019-10-02 18:51:50 INFO  TaskSetManager:54 - Finished task 0.0 in stage 20.0 (TID 20) in 8 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:50 INFO  TaskSchedulerImpl:54 - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2019-10-02 18:51:50 INFO  DAGScheduler:54 - ResultStage 20 (count at ReferenceData.scala:42) finished in 0.019 s
2019-10-02 18:51:50 INFO  DAGScheduler:54 - Job 13 finished: count at ReferenceData.scala:42, took 0.082984 s
---------------------------------------------------------------------------------------------------------
The Reference Table :Road_Surface_Conditions_Code : Loaded into HIVE with counts of 8
---------------------------------------------------------------------------------------------------------
2019-10-02 18:51:51 INFO  Utils$:51 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Road_Type_Code.csv)- Started @ 2019-10-02T18:51:51.006
2019-10-02 18:51:51 INFO  Utils$:58 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Road_Type_Code.csv)- Completed @ 2019-10-02T18:51:51.020
2019-10-02 18:51:51 INFO  Utils$:67 - Utils.OverwriteTable(Road_Type_Code)- Started @ 2019-10-02T18:51:51.064
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: drop_table : db=default tbl=road_type_code
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=road_type_code	
2019-10-02 18:51:51 INFO  hivemetastoressimpl:41 - deleting  file:/C:/temp/road_type_code
2019-10-02 18:51:51 INFO  TrashPolicyDefault:92 - Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2019-10-02 18:51:51 INFO  hivemetastoressimpl:53 - Deleted the diretory file:/C:/temp/road_type_code
2019-10-02 18:51:51 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:51 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:51 INFO  FileSourceStrategy:54 - Output Data Schema: struct<Type_Code: smallint, Type: string>
2019-10-02 18:51:51 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:51 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:51 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:51 INFO  MemoryStore:54 - Block broadcast_35 stored as values in memory (estimated size 293.7 KB, free 1962.6 MB)
2019-10-02 18:51:51 INFO  MemoryStore:54 - Block broadcast_35_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1962.6 MB)
2019-10-02 18:51:51 INFO  BlockManagerInfo:54 - Added broadcast_35_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.0 MB)
2019-10-02 18:51:51 INFO  SparkContext:54 - Created broadcast 35 from saveAsTable at Utils.scala:76
2019-10-02 18:51:51 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:51 INFO  SparkContext:54 - Starting job: saveAsTable at Utils.scala:76
2019-10-02 18:51:51 INFO  DAGScheduler:54 - Got job 14 (saveAsTable at Utils.scala:76) with 1 output partitions
2019-10-02 18:51:51 INFO  DAGScheduler:54 - Final stage: ResultStage 21 (saveAsTable at Utils.scala:76)
2019-10-02 18:51:51 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-10-02 18:51:51 INFO  DAGScheduler:54 - Missing parents: List()
2019-10-02 18:51:51 INFO  DAGScheduler:54 - Submitting ResultStage 21 (MapPartitionsRDD[79] at saveAsTable at Utils.scala:76), which has no missing parents
2019-10-02 18:51:51 INFO  MemoryStore:54 - Block broadcast_36 stored as values in memory (estimated size 158.1 KB, free 1962.5 MB)
2019-10-02 18:51:51 INFO  MemoryStore:54 - Block broadcast_36_piece0 stored as bytes in memory (estimated size 58.2 KB, free 1962.4 MB)
2019-10-02 18:51:51 INFO  BlockManagerInfo:54 - Added broadcast_36_piece0 in memory on user-PC:62456 (size: 58.2 KB, free: 1964.9 MB)
2019-10-02 18:51:51 INFO  SparkContext:54 - Created broadcast 36 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:51 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[79] at saveAsTable at Utils.scala:76) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:51 INFO  TaskSchedulerImpl:54 - Adding task set 21.0 with 1 tasks
2019-10-02 18:51:51 INFO  TaskSetManager:54 - Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 8371 bytes)
2019-10-02 18:51:51 INFO  Executor:54 - Running task 0.0 in stage 21.0 (TID 21)
2019-10-02 18:51:51 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Road_Type_Code.csv, range: 0-172, partition values: [empty row]
2019-10-02 18:51:51 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:51 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:51 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20191002185151_0021_m_000000_0' to file:/C:/temp/road_type_code/_temporary/0/task_20191002185151_0021_m_000000
2019-10-02 18:51:51 INFO  SparkHadoopMapRedUtil:54 - attempt_20191002185151_0021_m_000000_0: Committed
2019-10-02 18:51:51 INFO  Executor:54 - Finished task 0.0 in stage 21.0 (TID 21). 2849 bytes result sent to driver
2019-10-02 18:51:51 INFO  TaskSetManager:54 - Finished task 0.0 in stage 21.0 (TID 21) in 223 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:51 INFO  TaskSchedulerImpl:54 - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2019-10-02 18:51:51 INFO  DAGScheduler:54 - ResultStage 21 (saveAsTable at Utils.scala:76) finished in 0.306 s
2019-10-02 18:51:51 INFO  DAGScheduler:54 - Job 14 finished: saveAsTable at Utils.scala:76, took 0.307640 s
2019-10-02 18:51:51 INFO  FileFormatWriter:54 - Job null committed.
2019-10-02 18:51:51 INFO  FileFormatWriter:54 - Finished processing stats for job null.
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:51 INFO  HiveExternalCatalog:54 - Persisting file based data source table `default`.`road_type_code` into Hive metastore in Hive compatible format.
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: create_table: Table(tableName:road_type_code, dbName:default, owner:user, createTime:1570038711, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/road_type_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=create_table: Table(tableName:road_type_code, dbName:default, owner:user, createTime:1570038711, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/road_type_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:51 INFO  AlterTableRecoverPartitionsCommand:54 - Recover all the partitions in file:/C:/temp/road_type_code
2019-10-02 18:51:51 INFO  AlterTableRecoverPartitionsCommand:54 - Found 1 partitions in file:/C:/temp/road_type_code
2019-10-02 18:51:51 INFO  AlterTableRecoverPartitionsCommand:54 - Finished to gather the fast stats for all 1 partitions.
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:51 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:51 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: add_partitions
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=add_partitions	
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=road_type_code
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=road_type_code	
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: alter_table: db=default tbl=road_type_code newtbl=road_type_code
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=road_type_code newtbl=road_type_code	
2019-10-02 18:51:52 INFO  AlterTableRecoverPartitionsCommand:54 - Recovered all partitions (1).
2019-10-02 18:51:52 INFO  Utils$:77 - Utils.OverwriteTable(Road_Type_Code)- Completed @ 2019-10-02T18:51:52.089
2019-10-02 18:51:52 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:52 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:52 INFO  FileSourceStrategy:54 - Output Data Schema: struct<>
2019-10-02 18:51:52 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:52 INFO  MemoryStore:54 - Block broadcast_37 stored as values in memory (estimated size 293.7 KB, free 1962.1 MB)
2019-10-02 18:51:52 INFO  MemoryStore:54 - Block broadcast_37_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1962.1 MB)
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Added broadcast_37_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1964.9 MB)
2019-10-02 18:51:52 INFO  SparkContext:54 - Created broadcast 37 from count at ReferenceData.scala:42
2019-10-02 18:51:52 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:52 INFO  SparkContext:54 - Starting job: count at ReferenceData.scala:42
2019-10-02 18:51:52 INFO  DAGScheduler:54 - Registering RDD 84 (count at ReferenceData.scala:42)
2019-10-02 18:51:52 INFO  DAGScheduler:54 - Got job 15 (count at ReferenceData.scala:42) with 1 output partitions
2019-10-02 18:51:52 INFO  DAGScheduler:54 - Final stage: ResultStage 23 (count at ReferenceData.scala:42)
2019-10-02 18:51:52 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 22)
2019-10-02 18:51:52 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 22)
2019-10-02 18:51:52 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 22 (MapPartitionsRDD[84] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:52 INFO  MemoryStore:54 - Block broadcast_38 stored as values in memory (estimated size 14.4 KB, free 1962.1 MB)
2019-10-02 18:51:52 INFO  MemoryStore:54 - Block broadcast_38_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1962.1 MB)
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Added broadcast_38_piece0 in memory on user-PC:62456 (size: 8.1 KB, free: 1964.9 MB)
2019-10-02 18:51:52 INFO  SparkContext:54 - Created broadcast 38 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:52 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[84] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:52 INFO  TaskSchedulerImpl:54 - Adding task set 22.0 with 1 tasks
2019-10-02 18:51:52 INFO  TaskSetManager:54 - Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 8360 bytes)
2019-10-02 18:51:52 INFO  Executor:54 - Running task 0.0 in stage 22.0 (TID 22)
2019-10-02 18:51:52 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Road_Type_Code.csv, range: 0-172, partition values: [empty row]
2019-10-02 18:51:52 INFO  Executor:54 - Finished task 0.0 in stage 22.0 (TID 22). 1540 bytes result sent to driver
2019-10-02 18:51:52 INFO  TaskSetManager:54 - Finished task 0.0 in stage 22.0 (TID 22) in 36 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:52 INFO  TaskSchedulerImpl:54 - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2019-10-02 18:51:52 INFO  DAGScheduler:54 - ShuffleMapStage 22 (count at ReferenceData.scala:42) finished in 0.044 s
2019-10-02 18:51:52 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-10-02 18:51:52 INFO  DAGScheduler:54 - running: Set()
2019-10-02 18:51:52 INFO  DAGScheduler:54 - waiting: Set(ResultStage 23)
2019-10-02 18:51:52 INFO  DAGScheduler:54 - failed: Set()
2019-10-02 18:51:52 INFO  DAGScheduler:54 - Submitting ResultStage 23 (MapPartitionsRDD[87] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:52 INFO  MemoryStore:54 - Block broadcast_39 stored as values in memory (estimated size 7.3 KB, free 1962.1 MB)
2019-10-02 18:51:52 INFO  MemoryStore:54 - Block broadcast_39_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1962.1 MB)
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Added broadcast_39_piece0 in memory on user-PC:62456 (size: 3.8 KB, free: 1964.9 MB)
2019-10-02 18:51:52 INFO  SparkContext:54 - Created broadcast 39 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:52 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[87] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:52 INFO  TaskSchedulerImpl:54 - Adding task set 23.0 with 1 tasks
2019-10-02 18:51:52 INFO  TaskSetManager:54 - Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, ANY, 7754 bytes)
2019-10-02 18:51:52 INFO  Executor:54 - Running task 0.0 in stage 23.0 (TID 23)
2019-10-02 18:51:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2019-10-02 18:51:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-10-02 18:51:52 INFO  Executor:54 - Finished task 0.0 in stage 23.0 (TID 23). 1696 bytes result sent to driver
2019-10-02 18:51:52 INFO  TaskSetManager:54 - Finished task 0.0 in stage 23.0 (TID 23) in 5 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:52 INFO  TaskSchedulerImpl:54 - Removed TaskSet 23.0, whose tasks have all completed, from pool 
2019-10-02 18:51:52 INFO  DAGScheduler:54 - ResultStage 23 (count at ReferenceData.scala:42) finished in 0.010 s
2019-10-02 18:51:52 INFO  DAGScheduler:54 - Job 15 finished: count at ReferenceData.scala:42, took 0.058102 s
---------------------------------------------------------------------------------------------------------
The Reference Table :Road_Type_Code : Loaded into HIVE with counts of 8
---------------------------------------------------------------------------------------------------------
2019-10-02 18:51:52 INFO  Utils$:51 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Sex_of_Casualty_Code.csv)- Started @ 2019-10-02T18:51:52.224
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 870
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 719
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 791
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 793
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 518
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 688
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 663
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 860
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 480
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 499
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 729
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 827
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 606
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 585
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 614
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 821
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 762
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 803
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 681
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 747
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 727
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 806
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 808
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 502
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 810
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 694
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 561
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 751
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 546
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 765
2019-10-02 18:51:52 INFO  Utils$:58 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Sex_of_Casualty_Code.csv)- Completed @ 2019-10-02T18:51:52.262
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_25_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1964.9 MB)
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 607
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 683
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 768
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_30_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1964.9 MB)
2019-10-02 18:51:52 INFO  Utils$:67 - Utils.OverwriteTable(Sex_of_Casualty_Code)- Started @ 2019-10-02T18:51:52.292
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 864
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_36_piece0 on user-PC:62456 in memory (size: 58.2 KB, free: 1965.0 MB)
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 593
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 623
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_32_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1965.0 MB)
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 744
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 724
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 769
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 826
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 742
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 519
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 814
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 635
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 536
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 557
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 788
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 823
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 642
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 567
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 562
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 746
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 507
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 732
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 678
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 822
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 699
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 662
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 713
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 736
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 794
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_27_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1965.0 MB)
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 665
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned shuffle 6
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 596
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 625
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 608
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 510
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 544
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 589
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 594
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 584
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 830
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 640
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 641
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 579
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 781
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 533
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 659
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 705
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 482
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 525
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 548
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 745
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 818
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 650
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 757
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 573
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 760
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 506
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 619
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 503
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 835
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 677
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 799
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 707
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 668
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 868
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 673
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 697
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 796
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 572
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 672
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 666
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 702
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 728
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 754
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 549
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 776
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 856
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 610
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 801
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 558
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 731
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned shuffle 5
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 858
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 524
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 802
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 564
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 512
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 825
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 733
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 633
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 508
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 670
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 526
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 656
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 859
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 494
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 617
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 812
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 609
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 682
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 795
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 637
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 846
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 716
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 815
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 750
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 680
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 866
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 576
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 605
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 478
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 708
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 831
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 485
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 577
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 700
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 775
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_35_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1965.1 MB)
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 554
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 730
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 484
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 735
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 855
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 488
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 720
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 574
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_28_piece0 on user-PC:62456 in memory (size: 8.1 KB, free: 1965.1 MB)
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 664
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 785
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 779
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 845
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 639
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 568
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 613
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 646
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 621
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 763
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 654
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 671
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 842
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 734
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 738
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 777
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 805
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 657
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 759
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 687
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 532
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 534
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 575
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 695
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 811
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 487
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 492
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 514
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 853
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 712
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 495
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 560
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: drop_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_29_piece0 on user-PC:62456 in memory (size: 3.8 KB, free: 1965.1 MB)
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 807
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 622
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 789
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 714
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 715
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_34_piece0 on user-PC:62456 in memory (size: 3.8 KB, free: 1965.1 MB)
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 836
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 711
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 638
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 600
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 758
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 783
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 496
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 629
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 582
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 566
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 627
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 862
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 692
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 780
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 620
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 832
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 773
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 684
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 717
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 550
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 847
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 685
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 517
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 505
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 804
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_24_piece0 on user-PC:62456 in memory (size: 3.8 KB, free: 1965.1 MB)
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 570
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 837
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 578
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 718
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 602
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 528
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 863
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 603
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 786
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 511
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 753
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 706
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 537
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 658
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 857
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 515
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 563
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 611
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 645
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned shuffle 7
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 541
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 555
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 782
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 520
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 661
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 483
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 651
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 604
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 542
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 797
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 772
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 559
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 849
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 674
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 527
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 741
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 531
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 813
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 530
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 590
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 709
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 686
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 739
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 787
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 497
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 792
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 710
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 723
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 581
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 588
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 493
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 861
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 522
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 500
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 819
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 798
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_31_piece0 on user-PC:62456 in memory (size: 58.2 KB, free: 1965.1 MB)
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 833
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 501
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 490
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_37_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1965.2 MB)
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 479
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_23_piece0 on user-PC:62456 in memory (size: 8.1 KB, free: 1965.2 MB)
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 721
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 592
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 624
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 722
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 643
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 704
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 669
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 571
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 824
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 784
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 676
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 767
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 867
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 616
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 851
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned shuffle 4
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 690
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_38_piece0 on user-PC:62456 in memory (size: 8.1 KB, free: 1965.2 MB)
2019-10-02 18:51:52 INFO  hivemetastoressimpl:41 - deleting  file:/C:/temp/sex_of_casualty_code
2019-10-02 18:51:52 INFO  TrashPolicyDefault:92 - Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2019-10-02 18:51:52 INFO  hivemetastoressimpl:53 - Deleted the diretory file:/C:/temp/sex_of_casualty_code
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_22_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1965.2 MB)
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 547
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 595
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 543
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 618
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 848
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 631
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 703
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 647
2019-10-02 18:51:52 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:52 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:52 INFO  FileSourceStrategy:54 - Output Data Schema: struct<Type_Code: smallint, Type: string>
2019-10-02 18:51:52 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:52 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:52 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:52 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:52 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:52 INFO  MemoryStore:54 - Block broadcast_40 stored as values in memory (estimated size 293.7 KB, free 1964.5 MB)
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_33_piece0 on user-PC:62456 in memory (size: 8.1 KB, free: 1965.2 MB)
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 743
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 748
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 648
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 689
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 840
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 649
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 553
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 828
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 598
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 800
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 829
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 691
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 844
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 523
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 838
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 655
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 749
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 820
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 667
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 761
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 679
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 850
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 586
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 816
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 771
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 539
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 552
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 693
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 809
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 869
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 652
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 854
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 565
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 778
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 644
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 726
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 660
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 790
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 755
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 504
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 540
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 535
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 774
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_39_piece0 on user-PC:62456 in memory (size: 3.8 KB, free: 1965.2 MB)
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 545
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 865
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 597
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 756
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 516
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 740
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 489
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 843
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 551
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 529
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 569
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 653
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 766
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 521
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 583
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 591
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 612
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 481
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 725
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 599
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 486
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 817
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 580
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 636
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 498
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 509
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 764
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 538
2019-10-02 18:51:52 INFO  MemoryStore:54 - Block broadcast_40_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1964.7 MB)
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Removed broadcast_26_piece0 on user-PC:62456 in memory (size: 58.2 KB, free: 1965.3 MB)
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Added broadcast_40_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.3 MB)
2019-10-02 18:51:52 INFO  SparkContext:54 - Created broadcast 40 from saveAsTable at Utils.scala:76
2019-10-02 18:51:52 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 675
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 841
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 628
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 632
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 752
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 698
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 513
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 601
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 630
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 587
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 626
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 770
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 839
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 634
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 491
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 696
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 834
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 871
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 701
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 737
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 556
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 615
2019-10-02 18:51:52 INFO  ContextCleaner:54 - Cleaned accumulator 852
2019-10-02 18:51:52 INFO  SparkContext:54 - Starting job: saveAsTable at Utils.scala:76
2019-10-02 18:51:52 INFO  DAGScheduler:54 - Got job 16 (saveAsTable at Utils.scala:76) with 1 output partitions
2019-10-02 18:51:52 INFO  DAGScheduler:54 - Final stage: ResultStage 24 (saveAsTable at Utils.scala:76)
2019-10-02 18:51:52 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-10-02 18:51:52 INFO  DAGScheduler:54 - Missing parents: List()
2019-10-02 18:51:52 INFO  DAGScheduler:54 - Submitting ResultStage 24 (MapPartitionsRDD[90] at saveAsTable at Utils.scala:76), which has no missing parents
2019-10-02 18:51:52 INFO  MemoryStore:54 - Block broadcast_41 stored as values in memory (estimated size 158.1 KB, free 1964.5 MB)
2019-10-02 18:51:52 INFO  MemoryStore:54 - Block broadcast_41_piece0 stored as bytes in memory (estimated size 58.2 KB, free 1964.5 MB)
2019-10-02 18:51:52 INFO  BlockManagerInfo:54 - Added broadcast_41_piece0 in memory on user-PC:62456 (size: 58.2 KB, free: 1965.2 MB)
2019-10-02 18:51:52 INFO  SparkContext:54 - Created broadcast 41 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:52 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[90] at saveAsTable at Utils.scala:76) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:52 INFO  TaskSchedulerImpl:54 - Adding task set 24.0 with 1 tasks
2019-10-02 18:51:52 INFO  TaskSetManager:54 - Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 8377 bytes)
2019-10-02 18:51:52 INFO  Executor:54 - Running task 0.0 in stage 24.0 (TID 24)
2019-10-02 18:51:52 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Sex_of_Casualty_Code.csv, range: 0-63, partition values: [empty row]
2019-10-02 18:51:52 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:52 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:52 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20191002185152_0024_m_000000_0' to file:/C:/temp/sex_of_casualty_code/_temporary/0/task_20191002185152_0024_m_000000
2019-10-02 18:51:52 INFO  SparkHadoopMapRedUtil:54 - attempt_20191002185152_0024_m_000000_0: Committed
2019-10-02 18:51:52 INFO  Executor:54 - Finished task 0.0 in stage 24.0 (TID 24). 2849 bytes result sent to driver
2019-10-02 18:51:52 INFO  TaskSetManager:54 - Finished task 0.0 in stage 24.0 (TID 24) in 143 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:52 INFO  TaskSchedulerImpl:54 - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2019-10-02 18:51:52 INFO  DAGScheduler:54 - ResultStage 24 (saveAsTable at Utils.scala:76) finished in 0.190 s
2019-10-02 18:51:52 INFO  DAGScheduler:54 - Job 16 finished: saveAsTable at Utils.scala:76, took 0.194707 s
2019-10-02 18:51:53 INFO  FileFormatWriter:54 - Job null committed.
2019-10-02 18:51:53 INFO  FileFormatWriter:54 - Finished processing stats for job null.
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:53 INFO  HiveExternalCatalog:54 - Persisting file based data source table `default`.`sex_of_casualty_code` into Hive metastore in Hive compatible format.
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: create_table: Table(tableName:sex_of_casualty_code, dbName:default, owner:user, createTime:1570038712, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/sex_of_casualty_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=create_table: Table(tableName:sex_of_casualty_code, dbName:default, owner:user, createTime:1570038712, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/sex_of_casualty_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:53 INFO  AlterTableRecoverPartitionsCommand:54 - Recover all the partitions in file:/C:/temp/sex_of_casualty_code
2019-10-02 18:51:53 INFO  AlterTableRecoverPartitionsCommand:54 - Found 1 partitions in file:/C:/temp/sex_of_casualty_code
2019-10-02 18:51:53 INFO  AlterTableRecoverPartitionsCommand:54 - Finished to gather the fast stats for all 1 partitions.
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: add_partitions
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=add_partitions	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_casualty_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_casualty_code	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: alter_table: db=default tbl=sex_of_casualty_code newtbl=sex_of_casualty_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=sex_of_casualty_code newtbl=sex_of_casualty_code	
2019-10-02 18:51:53 INFO  AlterTableRecoverPartitionsCommand:54 - Recovered all partitions (1).
2019-10-02 18:51:53 INFO  Utils$:77 - Utils.OverwriteTable(Sex_of_Casualty_Code)- Completed @ 2019-10-02T18:51:53.515
2019-10-02 18:51:53 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:53 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:53 INFO  FileSourceStrategy:54 - Output Data Schema: struct<>
2019-10-02 18:51:53 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:53 INFO  MemoryStore:54 - Block broadcast_42 stored as values in memory (estimated size 293.7 KB, free 1964.2 MB)
2019-10-02 18:51:53 INFO  MemoryStore:54 - Block broadcast_42_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1964.2 MB)
2019-10-02 18:51:53 INFO  BlockManagerInfo:54 - Added broadcast_42_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.2 MB)
2019-10-02 18:51:53 INFO  SparkContext:54 - Created broadcast 42 from count at ReferenceData.scala:42
2019-10-02 18:51:53 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:53 INFO  SparkContext:54 - Starting job: count at ReferenceData.scala:42
2019-10-02 18:51:53 INFO  DAGScheduler:54 - Registering RDD 95 (count at ReferenceData.scala:42)
2019-10-02 18:51:53 INFO  DAGScheduler:54 - Got job 17 (count at ReferenceData.scala:42) with 1 output partitions
2019-10-02 18:51:53 INFO  DAGScheduler:54 - Final stage: ResultStage 26 (count at ReferenceData.scala:42)
2019-10-02 18:51:53 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 25)
2019-10-02 18:51:53 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 25)
2019-10-02 18:51:53 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 25 (MapPartitionsRDD[95] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:53 INFO  MemoryStore:54 - Block broadcast_43 stored as values in memory (estimated size 14.4 KB, free 1964.1 MB)
2019-10-02 18:51:53 INFO  MemoryStore:54 - Block broadcast_43_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1964.1 MB)
2019-10-02 18:51:53 INFO  BlockManagerInfo:54 - Added broadcast_43_piece0 in memory on user-PC:62456 (size: 8.1 KB, free: 1965.2 MB)
2019-10-02 18:51:53 INFO  SparkContext:54 - Created broadcast 43 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:53 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[95] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:53 INFO  TaskSchedulerImpl:54 - Adding task set 25.0 with 1 tasks
2019-10-02 18:51:53 INFO  TaskSetManager:54 - Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 8366 bytes)
2019-10-02 18:51:53 INFO  Executor:54 - Running task 0.0 in stage 25.0 (TID 25)
2019-10-02 18:51:53 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Sex_of_Casualty_Code.csv, range: 0-63, partition values: [empty row]
2019-10-02 18:51:53 INFO  Executor:54 - Finished task 0.0 in stage 25.0 (TID 25). 1540 bytes result sent to driver
2019-10-02 18:51:53 INFO  TaskSetManager:54 - Finished task 0.0 in stage 25.0 (TID 25) in 25 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:53 INFO  TaskSchedulerImpl:54 - Removed TaskSet 25.0, whose tasks have all completed, from pool 
2019-10-02 18:51:53 INFO  DAGScheduler:54 - ShuffleMapStage 25 (count at ReferenceData.scala:42) finished in 0.030 s
2019-10-02 18:51:53 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-10-02 18:51:53 INFO  DAGScheduler:54 - running: Set()
2019-10-02 18:51:53 INFO  DAGScheduler:54 - waiting: Set(ResultStage 26)
2019-10-02 18:51:53 INFO  DAGScheduler:54 - failed: Set()
2019-10-02 18:51:53 INFO  DAGScheduler:54 - Submitting ResultStage 26 (MapPartitionsRDD[98] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:53 INFO  MemoryStore:54 - Block broadcast_44 stored as values in memory (estimated size 7.3 KB, free 1964.1 MB)
2019-10-02 18:51:53 INFO  MemoryStore:54 - Block broadcast_44_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1964.1 MB)
2019-10-02 18:51:53 INFO  BlockManagerInfo:54 - Added broadcast_44_piece0 in memory on user-PC:62456 (size: 3.8 KB, free: 1965.2 MB)
2019-10-02 18:51:53 INFO  SparkContext:54 - Created broadcast 44 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:53 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[98] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:53 INFO  TaskSchedulerImpl:54 - Adding task set 26.0 with 1 tasks
2019-10-02 18:51:53 INFO  TaskSetManager:54 - Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, ANY, 7754 bytes)
2019-10-02 18:51:53 INFO  Executor:54 - Running task 0.0 in stage 26.0 (TID 26)
2019-10-02 18:51:53 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2019-10-02 18:51:53 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2019-10-02 18:51:53 INFO  Executor:54 - Finished task 0.0 in stage 26.0 (TID 26). 1696 bytes result sent to driver
2019-10-02 18:51:53 INFO  TaskSetManager:54 - Finished task 0.0 in stage 26.0 (TID 26) in 8 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:53 INFO  TaskSchedulerImpl:54 - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2019-10-02 18:51:53 INFO  DAGScheduler:54 - ResultStage 26 (count at ReferenceData.scala:42) finished in 0.012 s
2019-10-02 18:51:53 INFO  DAGScheduler:54 - Job 17 finished: count at ReferenceData.scala:42, took 0.048229 s
---------------------------------------------------------------------------------------------------------
The Reference Table :Sex_of_Casualty_Code : Loaded into HIVE with counts of 3
---------------------------------------------------------------------------------------------------------
2019-10-02 18:51:53 INFO  Utils$:51 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Sex_of_Driver_Code.csv)- Started @ 2019-10-02T18:51:53.646
2019-10-02 18:51:53 INFO  Utils$:58 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Sex_of_Driver_Code.csv)- Completed @ 2019-10-02T18:51:53.654
2019-10-02 18:51:53 INFO  Utils$:67 - Utils.OverwriteTable(Sex_of_Driver_Code)- Started @ 2019-10-02T18:51:53.681
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: drop_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:53 INFO  hivemetastoressimpl:41 - deleting  file:/C:/temp/sex_of_driver_code
2019-10-02 18:51:53 INFO  TrashPolicyDefault:92 - Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2019-10-02 18:51:53 INFO  hivemetastoressimpl:53 - Deleted the diretory file:/C:/temp/sex_of_driver_code
2019-10-02 18:51:53 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:53 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:53 INFO  FileSourceStrategy:54 - Output Data Schema: struct<Type_Code: smallint, Type: string>
2019-10-02 18:51:53 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:53 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:53 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:53 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:53 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:53 INFO  MemoryStore:54 - Block broadcast_45 stored as values in memory (estimated size 293.7 KB, free 1963.8 MB)
2019-10-02 18:51:54 INFO  MemoryStore:54 - Block broadcast_45_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1963.8 MB)
2019-10-02 18:51:54 INFO  BlockManagerInfo:54 - Added broadcast_45_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.1 MB)
2019-10-02 18:51:54 INFO  SparkContext:54 - Created broadcast 45 from saveAsTable at Utils.scala:76
2019-10-02 18:51:54 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:54 INFO  SparkContext:54 - Starting job: saveAsTable at Utils.scala:76
2019-10-02 18:51:54 INFO  DAGScheduler:54 - Got job 18 (saveAsTable at Utils.scala:76) with 1 output partitions
2019-10-02 18:51:54 INFO  DAGScheduler:54 - Final stage: ResultStage 27 (saveAsTable at Utils.scala:76)
2019-10-02 18:51:54 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-10-02 18:51:54 INFO  DAGScheduler:54 - Missing parents: List()
2019-10-02 18:51:54 INFO  DAGScheduler:54 - Submitting ResultStage 27 (MapPartitionsRDD[101] at saveAsTable at Utils.scala:76), which has no missing parents
2019-10-02 18:51:54 INFO  MemoryStore:54 - Block broadcast_46 stored as values in memory (estimated size 158.1 KB, free 1963.7 MB)
2019-10-02 18:51:54 INFO  MemoryStore:54 - Block broadcast_46_piece0 stored as bytes in memory (estimated size 58.2 KB, free 1963.6 MB)
2019-10-02 18:51:54 INFO  BlockManagerInfo:54 - Added broadcast_46_piece0 in memory on user-PC:62456 (size: 58.2 KB, free: 1965.1 MB)
2019-10-02 18:51:54 INFO  SparkContext:54 - Created broadcast 46 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:54 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[101] at saveAsTable at Utils.scala:76) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:54 INFO  TaskSchedulerImpl:54 - Adding task set 27.0 with 1 tasks
2019-10-02 18:51:54 INFO  TaskSetManager:54 - Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 8375 bytes)
2019-10-02 18:51:54 INFO  Executor:54 - Running task 0.0 in stage 27.0 (TID 27)
2019-10-02 18:51:54 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Sex_of_Driver_Code.csv, range: 0-76, partition values: [empty row]
2019-10-02 18:51:54 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:54 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:54 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20191002185154_0027_m_000000_0' to file:/C:/temp/sex_of_driver_code/_temporary/0/task_20191002185154_0027_m_000000
2019-10-02 18:51:54 INFO  SparkHadoopMapRedUtil:54 - attempt_20191002185154_0027_m_000000_0: Committed
2019-10-02 18:51:54 INFO  Executor:54 - Finished task 0.0 in stage 27.0 (TID 27). 2849 bytes result sent to driver
2019-10-02 18:51:54 INFO  TaskSetManager:54 - Finished task 0.0 in stage 27.0 (TID 27) in 205 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:54 INFO  TaskSchedulerImpl:54 - Removed TaskSet 27.0, whose tasks have all completed, from pool 
2019-10-02 18:51:54 INFO  DAGScheduler:54 - ResultStage 27 (saveAsTable at Utils.scala:76) finished in 0.254 s
2019-10-02 18:51:54 INFO  DAGScheduler:54 - Job 18 finished: saveAsTable at Utils.scala:76, took 0.256785 s
2019-10-02 18:51:54 INFO  FileFormatWriter:54 - Job null committed.
2019-10-02 18:51:54 INFO  FileFormatWriter:54 - Finished processing stats for job null.
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:54 INFO  HiveExternalCatalog:54 - Persisting file based data source table `default`.`sex_of_driver_code` into Hive metastore in Hive compatible format.
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: create_table: Table(tableName:sex_of_driver_code, dbName:default, owner:user, createTime:1570038713, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/sex_of_driver_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=create_table: Table(tableName:sex_of_driver_code, dbName:default, owner:user, createTime:1570038713, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/sex_of_driver_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:54 INFO  AlterTableRecoverPartitionsCommand:54 - Recover all the partitions in file:/C:/temp/sex_of_driver_code
2019-10-02 18:51:54 INFO  AlterTableRecoverPartitionsCommand:54 - Found 1 partitions in file:/C:/temp/sex_of_driver_code
2019-10-02 18:51:54 INFO  AlterTableRecoverPartitionsCommand:54 - Finished to gather the fast stats for all 1 partitions.
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: add_partitions
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=add_partitions	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=sex_of_driver_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=sex_of_driver_code	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: alter_table: db=default tbl=sex_of_driver_code newtbl=sex_of_driver_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=sex_of_driver_code newtbl=sex_of_driver_code	
2019-10-02 18:51:54 INFO  AlterTableRecoverPartitionsCommand:54 - Recovered all partitions (1).
2019-10-02 18:51:54 INFO  Utils$:77 - Utils.OverwriteTable(Sex_of_Driver_Code)- Completed @ 2019-10-02T18:51:54.716
2019-10-02 18:51:54 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:54 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:54 INFO  FileSourceStrategy:54 - Output Data Schema: struct<>
2019-10-02 18:51:54 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:54 INFO  MemoryStore:54 - Block broadcast_47 stored as values in memory (estimated size 293.7 KB, free 1963.3 MB)
2019-10-02 18:51:54 INFO  MemoryStore:54 - Block broadcast_47_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1963.3 MB)
2019-10-02 18:51:54 INFO  BlockManagerInfo:54 - Added broadcast_47_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.1 MB)
2019-10-02 18:51:54 INFO  SparkContext:54 - Created broadcast 47 from count at ReferenceData.scala:42
2019-10-02 18:51:54 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:54 INFO  SparkContext:54 - Starting job: count at ReferenceData.scala:42
2019-10-02 18:51:54 INFO  DAGScheduler:54 - Registering RDD 106 (count at ReferenceData.scala:42)
2019-10-02 18:51:54 INFO  DAGScheduler:54 - Got job 19 (count at ReferenceData.scala:42) with 1 output partitions
2019-10-02 18:51:54 INFO  DAGScheduler:54 - Final stage: ResultStage 29 (count at ReferenceData.scala:42)
2019-10-02 18:51:54 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 28)
2019-10-02 18:51:54 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 28)
2019-10-02 18:51:54 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 28 (MapPartitionsRDD[106] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:54 INFO  MemoryStore:54 - Block broadcast_48 stored as values in memory (estimated size 14.4 KB, free 1963.3 MB)
2019-10-02 18:51:54 INFO  MemoryStore:54 - Block broadcast_48_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1963.3 MB)
2019-10-02 18:51:54 INFO  BlockManagerInfo:54 - Added broadcast_48_piece0 in memory on user-PC:62456 (size: 8.1 KB, free: 1965.0 MB)
2019-10-02 18:51:54 INFO  SparkContext:54 - Created broadcast 48 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:54 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[106] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:54 INFO  TaskSchedulerImpl:54 - Adding task set 28.0 with 1 tasks
2019-10-02 18:51:54 INFO  TaskSetManager:54 - Starting task 0.0 in stage 28.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 8364 bytes)
2019-10-02 18:51:54 INFO  Executor:54 - Running task 0.0 in stage 28.0 (TID 28)
2019-10-02 18:51:54 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Sex_of_Driver_Code.csv, range: 0-76, partition values: [empty row]
2019-10-02 18:51:54 INFO  Executor:54 - Finished task 0.0 in stage 28.0 (TID 28). 1540 bytes result sent to driver
2019-10-02 18:51:54 INFO  TaskSetManager:54 - Finished task 0.0 in stage 28.0 (TID 28) in 28 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:54 INFO  TaskSchedulerImpl:54 - Removed TaskSet 28.0, whose tasks have all completed, from pool 
2019-10-02 18:51:54 INFO  DAGScheduler:54 - ShuffleMapStage 28 (count at ReferenceData.scala:42) finished in 0.033 s
2019-10-02 18:51:54 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-10-02 18:51:54 INFO  DAGScheduler:54 - running: Set()
2019-10-02 18:51:54 INFO  DAGScheduler:54 - waiting: Set(ResultStage 29)
2019-10-02 18:51:54 INFO  DAGScheduler:54 - failed: Set()
2019-10-02 18:51:54 INFO  DAGScheduler:54 - Submitting ResultStage 29 (MapPartitionsRDD[109] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:54 INFO  MemoryStore:54 - Block broadcast_49 stored as values in memory (estimated size 7.3 KB, free 1963.3 MB)
2019-10-02 18:51:54 INFO  MemoryStore:54 - Block broadcast_49_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1963.3 MB)
2019-10-02 18:51:54 INFO  BlockManagerInfo:54 - Added broadcast_49_piece0 in memory on user-PC:62456 (size: 3.8 KB, free: 1965.0 MB)
2019-10-02 18:51:54 INFO  SparkContext:54 - Created broadcast 49 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:54 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[109] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:54 INFO  TaskSchedulerImpl:54 - Adding task set 29.0 with 1 tasks
2019-10-02 18:51:54 INFO  TaskSetManager:54 - Starting task 0.0 in stage 29.0 (TID 29, localhost, executor driver, partition 0, ANY, 7754 bytes)
2019-10-02 18:51:54 INFO  Executor:54 - Running task 0.0 in stage 29.0 (TID 29)
2019-10-02 18:51:54 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2019-10-02 18:51:54 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-10-02 18:51:54 INFO  Executor:54 - Finished task 0.0 in stage 29.0 (TID 29). 1696 bytes result sent to driver
2019-10-02 18:51:54 INFO  TaskSetManager:54 - Finished task 0.0 in stage 29.0 (TID 29) in 15 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:54 INFO  TaskSchedulerImpl:54 - Removed TaskSet 29.0, whose tasks have all completed, from pool 
2019-10-02 18:51:54 INFO  DAGScheduler:54 - ResultStage 29 (count at ReferenceData.scala:42) finished in 0.020 s
2019-10-02 18:51:54 INFO  DAGScheduler:54 - Job 19 finished: count at ReferenceData.scala:42, took 0.057242 s
---------------------------------------------------------------------------------------------------------
The Reference Table :Sex_of_Driver_Code : Loaded into HIVE with counts of 4
---------------------------------------------------------------------------------------------------------
2019-10-02 18:51:54 INFO  Utils$:51 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Vehicle_Manoeuvre_Code.csv)- Started @ 2019-10-02T18:51:54.829
2019-10-02 18:51:54 INFO  Utils$:58 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Vehicle_Manoeuvre_Code.csv)- Completed @ 2019-10-02T18:51:54.837
2019-10-02 18:51:54 INFO  Utils$:67 - Utils.OverwriteTable(Vehicle_Manoeuvre_Code)- Started @ 2019-10-02T18:51:54.864
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:54 INFO  HiveMetaStore:746 - 0: drop_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:54 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:55 INFO  hivemetastoressimpl:41 - deleting  file:/C:/temp/vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  TrashPolicyDefault:92 - Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2019-10-02 18:51:55 INFO  hivemetastoressimpl:53 - Deleted the diretory file:/C:/temp/vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:55 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:55 INFO  FileSourceStrategy:54 - Output Data Schema: struct<Type_Code: smallint, Type: string>
2019-10-02 18:51:55 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:55 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:55 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:55 INFO  MemoryStore:54 - Block broadcast_50 stored as values in memory (estimated size 293.7 KB, free 1963.0 MB)
2019-10-02 18:51:55 INFO  MemoryStore:54 - Block broadcast_50_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1963.0 MB)
2019-10-02 18:51:55 INFO  BlockManagerInfo:54 - Added broadcast_50_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.0 MB)
2019-10-02 18:51:55 INFO  SparkContext:54 - Created broadcast 50 from saveAsTable at Utils.scala:76
2019-10-02 18:51:55 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:55 INFO  SparkContext:54 - Starting job: saveAsTable at Utils.scala:76
2019-10-02 18:51:55 INFO  DAGScheduler:54 - Got job 20 (saveAsTable at Utils.scala:76) with 1 output partitions
2019-10-02 18:51:55 INFO  DAGScheduler:54 - Final stage: ResultStage 30 (saveAsTable at Utils.scala:76)
2019-10-02 18:51:55 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-10-02 18:51:55 INFO  DAGScheduler:54 - Missing parents: List()
2019-10-02 18:51:55 INFO  DAGScheduler:54 - Submitting ResultStage 30 (MapPartitionsRDD[112] at saveAsTable at Utils.scala:76), which has no missing parents
2019-10-02 18:51:55 INFO  MemoryStore:54 - Block broadcast_51 stored as values in memory (estimated size 158.1 KB, free 1962.8 MB)
2019-10-02 18:51:55 INFO  MemoryStore:54 - Block broadcast_51_piece0 stored as bytes in memory (estimated size 58.2 KB, free 1962.7 MB)
2019-10-02 18:51:55 INFO  BlockManagerInfo:54 - Added broadcast_51_piece0 in memory on user-PC:62456 (size: 58.2 KB, free: 1965.0 MB)
2019-10-02 18:51:55 INFO  SparkContext:54 - Created broadcast 51 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:55 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[112] at saveAsTable at Utils.scala:76) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:55 INFO  TaskSchedulerImpl:54 - Adding task set 30.0 with 1 tasks
2019-10-02 18:51:55 INFO  TaskSetManager:54 - Starting task 0.0 in stage 30.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 8379 bytes)
2019-10-02 18:51:55 INFO  Executor:54 - Running task 0.0 in stage 30.0 (TID 30)
2019-10-02 18:51:55 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Vehicle_Manoeuvre_Code.csv, range: 0-469, partition values: [empty row]
2019-10-02 18:51:55 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:55 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:55 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20191002185155_0030_m_000000_0' to file:/C:/temp/vehicle_manoeuvre_code/_temporary/0/task_20191002185155_0030_m_000000
2019-10-02 18:51:55 INFO  SparkHadoopMapRedUtil:54 - attempt_20191002185155_0030_m_000000_0: Committed
2019-10-02 18:51:55 INFO  Executor:54 - Finished task 0.0 in stage 30.0 (TID 30). 2849 bytes result sent to driver
2019-10-02 18:51:55 INFO  TaskSetManager:54 - Finished task 0.0 in stage 30.0 (TID 30) in 110 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:55 INFO  TaskSchedulerImpl:54 - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2019-10-02 18:51:55 INFO  DAGScheduler:54 - ResultStage 30 (saveAsTable at Utils.scala:76) finished in 0.135 s
2019-10-02 18:51:55 INFO  DAGScheduler:54 - Job 20 finished: saveAsTable at Utils.scala:76, took 0.138316 s
2019-10-02 18:51:55 INFO  FileFormatWriter:54 - Job null committed.
2019-10-02 18:51:55 INFO  FileFormatWriter:54 - Finished processing stats for job null.
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:55 INFO  HiveExternalCatalog:54 - Persisting file based data source table `default`.`vehicle_manoeuvre_code` into Hive metastore in Hive compatible format.
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: create_table: Table(tableName:vehicle_manoeuvre_code, dbName:default, owner:user, createTime:1570038715, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/vehicle_manoeuvre_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=create_table: Table(tableName:vehicle_manoeuvre_code, dbName:default, owner:user, createTime:1570038715, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/vehicle_manoeuvre_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:55 INFO  AlterTableRecoverPartitionsCommand:54 - Recover all the partitions in file:/C:/temp/vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  AlterTableRecoverPartitionsCommand:54 - Found 1 partitions in file:/C:/temp/vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  AlterTableRecoverPartitionsCommand:54 - Finished to gather the fast stats for all 1 partitions.
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: add_partitions
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=add_partitions	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_manoeuvre_code	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: alter_table: db=default tbl=vehicle_manoeuvre_code newtbl=vehicle_manoeuvre_code
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=vehicle_manoeuvre_code newtbl=vehicle_manoeuvre_code	
2019-10-02 18:51:55 INFO  AlterTableRecoverPartitionsCommand:54 - Recovered all partitions (1).
2019-10-02 18:51:55 INFO  Utils$:77 - Utils.OverwriteTable(Vehicle_Manoeuvre_Code)- Completed @ 2019-10-02T18:51:55.754
2019-10-02 18:51:55 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:55 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:55 INFO  FileSourceStrategy:54 - Output Data Schema: struct<>
2019-10-02 18:51:55 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:55 INFO  MemoryStore:54 - Block broadcast_52 stored as values in memory (estimated size 293.7 KB, free 1962.5 MB)
2019-10-02 18:51:55 INFO  MemoryStore:54 - Block broadcast_52_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1962.4 MB)
2019-10-02 18:51:55 INFO  BlockManagerInfo:54 - Added broadcast_52_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1964.9 MB)
2019-10-02 18:51:55 INFO  SparkContext:54 - Created broadcast 52 from count at ReferenceData.scala:42
2019-10-02 18:51:55 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:55 INFO  SparkContext:54 - Starting job: count at ReferenceData.scala:42
2019-10-02 18:51:55 INFO  DAGScheduler:54 - Registering RDD 117 (count at ReferenceData.scala:42)
2019-10-02 18:51:55 INFO  DAGScheduler:54 - Got job 21 (count at ReferenceData.scala:42) with 1 output partitions
2019-10-02 18:51:55 INFO  DAGScheduler:54 - Final stage: ResultStage 32 (count at ReferenceData.scala:42)
2019-10-02 18:51:55 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 31)
2019-10-02 18:51:55 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 31)
2019-10-02 18:51:55 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 31 (MapPartitionsRDD[117] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:55 INFO  MemoryStore:54 - Block broadcast_53 stored as values in memory (estimated size 14.4 KB, free 1962.4 MB)
2019-10-02 18:51:55 INFO  MemoryStore:54 - Block broadcast_53_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1962.4 MB)
2019-10-02 18:51:55 INFO  BlockManagerInfo:54 - Added broadcast_53_piece0 in memory on user-PC:62456 (size: 8.1 KB, free: 1964.9 MB)
2019-10-02 18:51:55 INFO  SparkContext:54 - Created broadcast 53 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:55 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[117] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:55 INFO  TaskSchedulerImpl:54 - Adding task set 31.0 with 1 tasks
2019-10-02 18:51:55 INFO  TaskSetManager:54 - Starting task 0.0 in stage 31.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 8368 bytes)
2019-10-02 18:51:55 INFO  Executor:54 - Running task 0.0 in stage 31.0 (TID 31)
2019-10-02 18:51:55 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Vehicle_Manoeuvre_Code.csv, range: 0-469, partition values: [empty row]
2019-10-02 18:51:55 INFO  Executor:54 - Finished task 0.0 in stage 31.0 (TID 31). 1540 bytes result sent to driver
2019-10-02 18:51:55 INFO  TaskSetManager:54 - Finished task 0.0 in stage 31.0 (TID 31) in 91 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:55 INFO  TaskSchedulerImpl:54 - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2019-10-02 18:51:55 INFO  DAGScheduler:54 - ShuffleMapStage 31 (count at ReferenceData.scala:42) finished in 0.098 s
2019-10-02 18:51:55 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-10-02 18:51:55 INFO  DAGScheduler:54 - running: Set()
2019-10-02 18:51:55 INFO  DAGScheduler:54 - waiting: Set(ResultStage 32)
2019-10-02 18:51:55 INFO  DAGScheduler:54 - failed: Set()
2019-10-02 18:51:55 INFO  DAGScheduler:54 - Submitting ResultStage 32 (MapPartitionsRDD[120] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:55 INFO  MemoryStore:54 - Block broadcast_54 stored as values in memory (estimated size 7.3 KB, free 1962.4 MB)
2019-10-02 18:51:55 INFO  MemoryStore:54 - Block broadcast_54_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1962.4 MB)
2019-10-02 18:51:55 INFO  BlockManagerInfo:54 - Added broadcast_54_piece0 in memory on user-PC:62456 (size: 3.8 KB, free: 1964.9 MB)
2019-10-02 18:51:55 INFO  SparkContext:54 - Created broadcast 54 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:55 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[120] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:55 INFO  TaskSchedulerImpl:54 - Adding task set 32.0 with 1 tasks
2019-10-02 18:51:55 INFO  TaskSetManager:54 - Starting task 0.0 in stage 32.0 (TID 32, localhost, executor driver, partition 0, ANY, 7754 bytes)
2019-10-02 18:51:55 INFO  Executor:54 - Running task 0.0 in stage 32.0 (TID 32)
2019-10-02 18:51:55 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2019-10-02 18:51:55 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2019-10-02 18:51:55 INFO  Executor:54 - Finished task 0.0 in stage 32.0 (TID 32). 1782 bytes result sent to driver
2019-10-02 18:51:55 INFO  TaskSetManager:54 - Finished task 0.0 in stage 32.0 (TID 32) in 10 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:55 INFO  TaskSchedulerImpl:54 - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2019-10-02 18:51:55 INFO  DAGScheduler:54 - ResultStage 32 (count at ReferenceData.scala:42) finished in 0.020 s
2019-10-02 18:51:55 INFO  DAGScheduler:54 - Job 21 finished: count at ReferenceData.scala:42, took 0.122783 s
---------------------------------------------------------------------------------------------------------
The Reference Table :Vehicle_Manoeuvre_Code : Loaded into HIVE with counts of 19
---------------------------------------------------------------------------------------------------------
2019-10-02 18:51:55 INFO  Utils$:51 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Vehicle_Type_Code.csv)- Started @ 2019-10-02T18:51:55.953
2019-10-02 18:51:55 INFO  Utils$:58 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Vehicle_Type_Code.csv)- Completed @ 2019-10-02T18:51:55.961
2019-10-02 18:51:55 INFO  Utils$:67 - Utils.OverwriteTable(Vehicle_Type_Code)- Started @ 2019-10-02T18:51:55.977
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:55 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:55 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: drop_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  hivemetastoressimpl:41 - deleting  file:/C:/temp/vehicle_type_code
2019-10-02 18:51:56 INFO  TrashPolicyDefault:92 - Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2019-10-02 18:51:56 INFO  hivemetastoressimpl:53 - Deleted the diretory file:/C:/temp/vehicle_type_code
2019-10-02 18:51:56 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:56 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:56 INFO  FileSourceStrategy:54 - Output Data Schema: struct<Type_Code: smallint, Type: string>
2019-10-02 18:51:56 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:56 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:56 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:56 INFO  MemoryStore:54 - Block broadcast_55 stored as values in memory (estimated size 293.7 KB, free 1962.1 MB)
2019-10-02 18:51:56 INFO  MemoryStore:54 - Block broadcast_55_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1962.1 MB)
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Added broadcast_55_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1964.9 MB)
2019-10-02 18:51:56 INFO  SparkContext:54 - Created broadcast 55 from saveAsTable at Utils.scala:76
2019-10-02 18:51:56 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:56 INFO  SparkContext:54 - Starting job: saveAsTable at Utils.scala:76
2019-10-02 18:51:56 INFO  DAGScheduler:54 - Got job 22 (saveAsTable at Utils.scala:76) with 1 output partitions
2019-10-02 18:51:56 INFO  DAGScheduler:54 - Final stage: ResultStage 33 (saveAsTable at Utils.scala:76)
2019-10-02 18:51:56 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-10-02 18:51:56 INFO  DAGScheduler:54 - Missing parents: List()
2019-10-02 18:51:56 INFO  DAGScheduler:54 - Submitting ResultStage 33 (MapPartitionsRDD[123] at saveAsTable at Utils.scala:76), which has no missing parents
2019-10-02 18:51:56 INFO  MemoryStore:54 - Block broadcast_56 stored as values in memory (estimated size 158.1 KB, free 1961.9 MB)
2019-10-02 18:51:56 INFO  MemoryStore:54 - Block broadcast_56_piece0 stored as bytes in memory (estimated size 58.2 KB, free 1961.9 MB)
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Added broadcast_56_piece0 in memory on user-PC:62456 (size: 58.2 KB, free: 1964.9 MB)
2019-10-02 18:51:56 INFO  SparkContext:54 - Created broadcast 56 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:56 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[123] at saveAsTable at Utils.scala:76) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:56 INFO  TaskSchedulerImpl:54 - Adding task set 33.0 with 1 tasks
2019-10-02 18:51:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 33.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 8374 bytes)
2019-10-02 18:51:56 INFO  Executor:54 - Running task 0.0 in stage 33.0 (TID 33)
2019-10-02 18:51:56 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Vehicle_Type_Code.csv, range: 0-602, partition values: [empty row]
2019-10-02 18:51:56 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:56 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:56 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20191002185156_0033_m_000000_0' to file:/C:/temp/vehicle_type_code/_temporary/0/task_20191002185156_0033_m_000000
2019-10-02 18:51:56 INFO  SparkHadoopMapRedUtil:54 - attempt_20191002185156_0033_m_000000_0: Committed
2019-10-02 18:51:56 INFO  Executor:54 - Finished task 0.0 in stage 33.0 (TID 33). 2849 bytes result sent to driver
2019-10-02 18:51:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 33.0 (TID 33) in 118 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:56 INFO  TaskSchedulerImpl:54 - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2019-10-02 18:51:56 INFO  DAGScheduler:54 - ResultStage 33 (saveAsTable at Utils.scala:76) finished in 0.154 s
2019-10-02 18:51:56 INFO  DAGScheduler:54 - Job 22 finished: saveAsTable at Utils.scala:76, took 0.156427 s
2019-10-02 18:51:56 INFO  FileFormatWriter:54 - Job null committed.
2019-10-02 18:51:56 INFO  FileFormatWriter:54 - Finished processing stats for job null.
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  HiveExternalCatalog:54 - Persisting file based data source table `default`.`vehicle_type_code` into Hive metastore in Hive compatible format.
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: create_table: Table(tableName:vehicle_type_code, dbName:default, owner:user, createTime:1570038716, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/vehicle_type_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=create_table: Table(tableName:vehicle_type_code, dbName:default, owner:user, createTime:1570038716, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/vehicle_type_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  AlterTableRecoverPartitionsCommand:54 - Recover all the partitions in file:/C:/temp/vehicle_type_code
2019-10-02 18:51:56 INFO  AlterTableRecoverPartitionsCommand:54 - Found 1 partitions in file:/C:/temp/vehicle_type_code
2019-10-02 18:51:56 INFO  AlterTableRecoverPartitionsCommand:54 - Finished to gather the fast stats for all 1 partitions.
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: add_partitions
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=add_partitions	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  HiveMetaStore:746 - 0: alter_table: db=default tbl=vehicle_type_code newtbl=vehicle_type_code
2019-10-02 18:51:56 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=vehicle_type_code newtbl=vehicle_type_code	
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1039
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1140
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 888
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1004
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1048
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1130
2019-10-02 18:51:56 INFO  AlterTableRecoverPartitionsCommand:54 - Recovered all partitions (1).
2019-10-02 18:51:56 INFO  Utils$:77 - Utils.OverwriteTable(Vehicle_Type_Code)- Completed @ 2019-10-02T18:51:56.836
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned shuffle 9
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 943
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 997
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1073
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1179
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1021
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 895
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Removed broadcast_42_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1964.9 MB)
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1132
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1010
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1111
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1142
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 882
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 985
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1008
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1026
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1064
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 975
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1012
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1079
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1198
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1215
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 893
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1105
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1208
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 890
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1150
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1127
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1219
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1043
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1233
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1087
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 906
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 983
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 953
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 875
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1116
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1129
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 883
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 981
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1186
2019-10-02 18:51:56 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:56 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:56 INFO  FileSourceStrategy:54 - Output Data Schema: struct<>
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Removed broadcast_52_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1964.9 MB)
2019-10-02 18:51:56 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 905
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 918
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1195
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1090
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1095
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1158
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1220
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1112
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1221
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 940
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1006
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1157
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1094
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1054
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1005
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 939
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1058
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1211
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1238
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1123
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned shuffle 8
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1115
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 944
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1069
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 878
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1106
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 896
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 974
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Removed broadcast_54_piece0 on user-PC:62456 in memory (size: 3.8 KB, free: 1964.9 MB)
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1076
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1182
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1080
2019-10-02 18:51:56 INFO  MemoryStore:54 - Block broadcast_57 stored as values in memory (estimated size 293.7 KB, free 1962.2 MB)
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Removed broadcast_50_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1964.9 MB)
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1063
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1136
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1099
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1194
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 972
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 935
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1102
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1168
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 891
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 904
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1210
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 948
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1191
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 874
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1036
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1189
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1217
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 914
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1051
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1159
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1015
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1049
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Removed broadcast_48_piece0 on user-PC:62456 in memory (size: 8.1 KB, free: 1964.9 MB)
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1197
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 925
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1070
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1231
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1088
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 901
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 995
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1167
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 969
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1170
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1226
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1128
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1109
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1230
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1062
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1013
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1034
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1216
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1228
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 931
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1214
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 873
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1147
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 911
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1089
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 960
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1224
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1050
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 937
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1164
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1178
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1174
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1091
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1072
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1097
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1014
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1001
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1046
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1061
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1146
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1222
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1234
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 919
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 957
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1068
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1223
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 900
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 923
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 950
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1180
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1045
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 991
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1171
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1172
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1055
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1040
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1038
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned shuffle 10
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 910
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 999
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1084
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 889
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1121
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 963
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1183
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 886
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1018
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1163
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 986
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 898
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1181
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 994
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1122
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1085
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1075
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1103
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1020
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1025
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Removed broadcast_45_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1965.0 MB)
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1131
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1229
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1022
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1237
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1017
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1193
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 916
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1120
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 913
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1151
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1188
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1047
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1235
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1092
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 892
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 884
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1074
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1077
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1030
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 996
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1041
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 993
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 979
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 978
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 945
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 954
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1065
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 959
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1160
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1213
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 917
2019-10-02 18:51:56 INFO  MemoryStore:54 - Block broadcast_57_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1962.8 MB)
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Added broadcast_57_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1964.9 MB)
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Removed broadcast_56_piece0 on user-PC:62456 in memory (size: 58.2 KB, free: 1965.0 MB)
2019-10-02 18:51:56 INFO  SparkContext:54 - Created broadcast 57 from count at ReferenceData.scala:42
2019-10-02 18:51:56 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 920
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 877
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Removed broadcast_51_piece0 on user-PC:62456 in memory (size: 58.2 KB, free: 1965.0 MB)
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Removed broadcast_40_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1965.1 MB)
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1037
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 947
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1138
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1042
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 876
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 899
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1113
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1007
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1035
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1125
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Removed broadcast_41_piece0 on user-PC:62456 in memory (size: 58.2 KB, free: 1965.1 MB)
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 902
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1135
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 924
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 915
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1114
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 961
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 922
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1126
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1192
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 879
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 934
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1225
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1031
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1107
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1023
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1137
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1227
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1153
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1053
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1098
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 881
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1218
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1057
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1166
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 928
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 921
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1155
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 966
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 885
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1101
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1149
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 989
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 907
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 903
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 912
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 929
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 946
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1052
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1161
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 932
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 992
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1141
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1185
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1196
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1093
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 988
2019-10-02 18:51:56 INFO  SparkContext:54 - Starting job: count at ReferenceData.scala:42
2019-10-02 18:51:56 INFO  DAGScheduler:54 - Registering RDD 128 (count at ReferenceData.scala:42)
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Removed broadcast_44_piece0 on user-PC:62456 in memory (size: 3.8 KB, free: 1965.1 MB)
2019-10-02 18:51:56 INFO  DAGScheduler:54 - Got job 23 (count at ReferenceData.scala:42) with 1 output partitions
2019-10-02 18:51:56 INFO  DAGScheduler:54 - Final stage: ResultStage 35 (count at ReferenceData.scala:42)
2019-10-02 18:51:56 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 34)
2019-10-02 18:51:56 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 34)
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1212
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 930
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 990
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1067
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 967
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1104
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1118
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1117
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 987
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1082
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1000
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1190
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1029
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1083
2019-10-02 18:51:56 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 34 (MapPartitionsRDD[128] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:56 INFO  MemoryStore:54 - Block broadcast_58 stored as values in memory (estimated size 14.4 KB, free 1963.8 MB)
2019-10-02 18:51:56 INFO  MemoryStore:54 - Block broadcast_58_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1963.8 MB)
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Added broadcast_58_piece0 in memory on user-PC:62456 (size: 8.1 KB, free: 1965.1 MB)
2019-10-02 18:51:56 INFO  SparkContext:54 - Created broadcast 58 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:56 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[128] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:56 INFO  TaskSchedulerImpl:54 - Adding task set 34.0 with 1 tasks
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Removed broadcast_43_piece0 on user-PC:62456 in memory (size: 8.1 KB, free: 1965.1 MB)
2019-10-02 18:51:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 34.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 8363 bytes)
2019-10-02 18:51:56 INFO  Executor:54 - Running task 0.0 in stage 34.0 (TID 34)
2019-10-02 18:51:56 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Vehicle_Type_Code.csv, range: 0-602, partition values: [empty row]
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Removed broadcast_46_piece0 on user-PC:62456 in memory (size: 58.2 KB, free: 1965.2 MB)
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1145
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 887
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1002
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1033
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1044
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1184
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1139
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1066
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 942
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1016
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1154
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1024
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1108
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1032
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1100
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1152
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 976
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1027
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1011
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1060
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 949
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1003
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1144
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 955
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1175
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 894
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 872
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1162
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 941
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1187
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 938
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1078
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 962
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Removed broadcast_49_piece0 on user-PC:62456 in memory (size: 3.8 KB, free: 1965.2 MB)
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1019
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 971
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 984
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 970
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1081
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1165
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 973
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 880
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1134
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1209
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 958
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 909
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 936
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1028
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1086
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1143
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 952
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Removed broadcast_53_piece0 on user-PC:62456 in memory (size: 8.1 KB, free: 1965.2 MB)
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 964
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 982
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1236
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1110
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 897
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 968
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1096
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1056
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 965
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1071
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Removed broadcast_47_piece0 on user-PC:62456 in memory (size: 24.0 KB, free: 1965.2 MB)
2019-10-02 18:51:56 INFO  Executor:54 - Finished task 0.0 in stage 34.0 (TID 34). 1540 bytes result sent to driver
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1133
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1176
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 998
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1059
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 908
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1156
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1239
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 980
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1232
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1009
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1148
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1177
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1124
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 956
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 926
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1169
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1119
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 951
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 977
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 927
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 1173
2019-10-02 18:51:56 INFO  ContextCleaner:54 - Cleaned accumulator 933
2019-10-02 18:51:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 34.0 (TID 34) in 29 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:56 INFO  TaskSchedulerImpl:54 - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2019-10-02 18:51:56 INFO  DAGScheduler:54 - ShuffleMapStage 34 (count at ReferenceData.scala:42) finished in 0.036 s
2019-10-02 18:51:56 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-10-02 18:51:56 INFO  DAGScheduler:54 - running: Set()
2019-10-02 18:51:56 INFO  DAGScheduler:54 - waiting: Set(ResultStage 35)
2019-10-02 18:51:56 INFO  DAGScheduler:54 - failed: Set()
2019-10-02 18:51:56 INFO  DAGScheduler:54 - Submitting ResultStage 35 (MapPartitionsRDD[131] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:56 INFO  MemoryStore:54 - Block broadcast_59 stored as values in memory (estimated size 7.3 KB, free 1964.3 MB)
2019-10-02 18:51:56 INFO  MemoryStore:54 - Block broadcast_59_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1964.3 MB)
2019-10-02 18:51:56 INFO  BlockManagerInfo:54 - Added broadcast_59_piece0 in memory on user-PC:62456 (size: 3.8 KB, free: 1965.2 MB)
2019-10-02 18:51:56 INFO  SparkContext:54 - Created broadcast 59 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:56 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[131] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:56 INFO  TaskSchedulerImpl:54 - Adding task set 35.0 with 1 tasks
2019-10-02 18:51:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 35.0 (TID 35, localhost, executor driver, partition 0, ANY, 7754 bytes)
2019-10-02 18:51:56 INFO  Executor:54 - Running task 0.0 in stage 35.0 (TID 35)
2019-10-02 18:51:56 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2019-10-02 18:51:56 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2019-10-02 18:51:56 INFO  Executor:54 - Finished task 0.0 in stage 35.0 (TID 35). 1739 bytes result sent to driver
2019-10-02 18:51:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 35.0 (TID 35) in 7 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:56 INFO  TaskSchedulerImpl:54 - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2019-10-02 18:51:56 INFO  DAGScheduler:54 - ResultStage 35 (count at ReferenceData.scala:42) finished in 0.011 s
2019-10-02 18:51:56 INFO  DAGScheduler:54 - Job 23 finished: count at ReferenceData.scala:42, took 0.055312 s
---------------------------------------------------------------------------------------------------------
The Reference Table :Vehicle_Type_Code : Loaded into HIVE with counts of 21
---------------------------------------------------------------------------------------------------------
2019-10-02 18:51:56 INFO  Utils$:51 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Weather_Conditions_Code.csv)- Started @ 2019-10-02T18:51:56.993
2019-10-02 18:51:57 INFO  Utils$:58 - Utils.ReadFromCSV(D:\Contracting\201909 - CWT Job Interview and Process\ReferenceData\Weather_Conditions_Code.csv)- Completed @ 2019-10-02T18:51:57.001
2019-10-02 18:51:57 INFO  Utils$:67 - Utils.OverwriteTable(Weather_Conditions_Code)- Started @ 2019-10-02T18:51:57.016
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: drop_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  hivemetastoressimpl:41 - deleting  file:/C:/temp/weather_conditions_code
2019-10-02 18:51:57 INFO  TrashPolicyDefault:92 - Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2019-10-02 18:51:57 INFO  hivemetastoressimpl:53 - Deleted the diretory file:/C:/temp/weather_conditions_code
2019-10-02 18:51:57 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:57 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:57 INFO  FileSourceStrategy:54 - Output Data Schema: struct<Type_Code: smallint, Type: string>
2019-10-02 18:51:57 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:57 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:57 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:57 INFO  MemoryStore:54 - Block broadcast_60 stored as values in memory (estimated size 293.7 KB, free 1964.0 MB)
2019-10-02 18:51:57 INFO  MemoryStore:54 - Block broadcast_60_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1964.0 MB)
2019-10-02 18:51:57 INFO  BlockManagerInfo:54 - Added broadcast_60_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.2 MB)
2019-10-02 18:51:57 INFO  SparkContext:54 - Created broadcast 60 from saveAsTable at Utils.scala:76
2019-10-02 18:51:57 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:57 INFO  SparkContext:54 - Starting job: saveAsTable at Utils.scala:76
2019-10-02 18:51:57 INFO  DAGScheduler:54 - Got job 24 (saveAsTable at Utils.scala:76) with 1 output partitions
2019-10-02 18:51:57 INFO  DAGScheduler:54 - Final stage: ResultStage 36 (saveAsTable at Utils.scala:76)
2019-10-02 18:51:57 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-10-02 18:51:57 INFO  DAGScheduler:54 - Missing parents: List()
2019-10-02 18:51:57 INFO  DAGScheduler:54 - Submitting ResultStage 36 (MapPartitionsRDD[134] at saveAsTable at Utils.scala:76), which has no missing parents
2019-10-02 18:51:57 INFO  MemoryStore:54 - Block broadcast_61 stored as values in memory (estimated size 158.1 KB, free 1963.9 MB)
2019-10-02 18:51:57 INFO  MemoryStore:54 - Block broadcast_61_piece0 stored as bytes in memory (estimated size 58.2 KB, free 1963.8 MB)
2019-10-02 18:51:57 INFO  BlockManagerInfo:54 - Added broadcast_61_piece0 in memory on user-PC:62456 (size: 58.2 KB, free: 1965.1 MB)
2019-10-02 18:51:57 INFO  SparkContext:54 - Created broadcast 61 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:57 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[134] at saveAsTable at Utils.scala:76) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:57 INFO  TaskSchedulerImpl:54 - Adding task set 36.0 with 1 tasks
2019-10-02 18:51:57 INFO  TaskSetManager:54 - Starting task 0.0 in stage 36.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 8380 bytes)
2019-10-02 18:51:57 INFO  Executor:54 - Running task 0.0 in stage 36.0 (TID 36)
2019-10-02 18:51:57 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Weather_Conditions_Code.csv, range: 0-221, partition values: [empty row]
2019-10-02 18:51:57 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2019-10-02 18:51:57 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-10-02 18:51:57 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20191002185157_0036_m_000000_0' to file:/C:/temp/weather_conditions_code/_temporary/0/task_20191002185157_0036_m_000000
2019-10-02 18:51:57 INFO  SparkHadoopMapRedUtil:54 - attempt_20191002185157_0036_m_000000_0: Committed
2019-10-02 18:51:57 INFO  Executor:54 - Finished task 0.0 in stage 36.0 (TID 36). 2849 bytes result sent to driver
2019-10-02 18:51:57 INFO  TaskSetManager:54 - Finished task 0.0 in stage 36.0 (TID 36) in 110 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:57 INFO  TaskSchedulerImpl:54 - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2019-10-02 18:51:57 INFO  DAGScheduler:54 - ResultStage 36 (saveAsTable at Utils.scala:76) finished in 0.142 s
2019-10-02 18:51:57 INFO  DAGScheduler:54 - Job 24 finished: saveAsTable at Utils.scala:76, took 0.145037 s
2019-10-02 18:51:57 INFO  FileFormatWriter:54 - Job null committed.
2019-10-02 18:51:57 INFO  FileFormatWriter:54 - Finished processing stats for job null.
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  HiveExternalCatalog:54 - Persisting file based data source table `default`.`weather_conditions_code` into Hive metastore in Hive compatible format.
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: create_table: Table(tableName:weather_conditions_code, dbName:default, owner:user, createTime:1570038717, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/weather_conditions_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=create_table: Table(tableName:weather_conditions_code, dbName:default, owner:user, createTime:1570038717, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:Type_Code, type:smallint, comment:null), FieldSchema(name:Type, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{path=file:/C:/temp/weather_conditions_code, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:IngestYear, type:string, comment:null), FieldSchema(name:IngestMonth, type:string, comment:null), FieldSchema(name:IngestDay, type:string, comment:null)], parameters:{spark.sql.sources.schema.numPartCols=3, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"Type_Code","type":"short","nullable":true,"metadata":{}},{"name":"Type","type":"string","nullable":true,"metadata":{}},{"name":"IngestYear","type":"string","nullable":true,"metadata":{}},{"name":"IngestMonth","type":"string","nullable":true,"metadata":{}},{"name":"IngestDay","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.partCol.0=IngestYear, spark.sql.sources.schema.partCol.2=IngestDay, spark.sql.sources.schema.partCol.1=IngestMonth, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=orc, spark.sql.create.version=2.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  AlterTableRecoverPartitionsCommand:54 - Recover all the partitions in file:/C:/temp/weather_conditions_code
2019-10-02 18:51:57 INFO  AlterTableRecoverPartitionsCommand:54 - Found 1 partitions in file:/C:/temp/weather_conditions_code
2019-10-02 18:51:57 INFO  AlterTableRecoverPartitionsCommand:54 - Finished to gather the fast stats for all 1 partitions.
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: add_partitions
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=add_partitions	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_database: default
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_database: default	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: get_table : db=default tbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=get_table : db=default tbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  HiveMetaStore:746 - 0: alter_table: db=default tbl=weather_conditions_code newtbl=weather_conditions_code
2019-10-02 18:51:57 INFO  audit:371 - ugi=user	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=weather_conditions_code newtbl=weather_conditions_code	
2019-10-02 18:51:57 INFO  AlterTableRecoverPartitionsCommand:54 - Recovered all partitions (1).
2019-10-02 18:51:57 INFO  Utils$:77 - Utils.OverwriteTable(Weather_Conditions_Code)- Completed @ 2019-10-02T18:51:57.797
2019-10-02 18:51:57 INFO  FileSourceStrategy:54 - Pruning directories with: 
2019-10-02 18:51:57 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2019-10-02 18:51:57 INFO  FileSourceStrategy:54 - Output Data Schema: struct<>
2019-10-02 18:51:57 INFO  FileSourceScanExec:54 - Pushed Filters: 
2019-10-02 18:51:57 INFO  MemoryStore:54 - Block broadcast_62 stored as values in memory (estimated size 293.7 KB, free 1963.5 MB)
2019-10-02 18:51:57 INFO  MemoryStore:54 - Block broadcast_62_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1963.5 MB)
2019-10-02 18:51:57 INFO  BlockManagerInfo:54 - Added broadcast_62_piece0 in memory on user-PC:62456 (size: 24.0 KB, free: 1965.1 MB)
2019-10-02 18:51:57 INFO  SparkContext:54 - Created broadcast 62 from count at ReferenceData.scala:42
2019-10-02 18:51:57 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-10-02 18:51:57 INFO  SparkContext:54 - Starting job: count at ReferenceData.scala:42
2019-10-02 18:51:57 INFO  DAGScheduler:54 - Registering RDD 139 (count at ReferenceData.scala:42)
2019-10-02 18:51:57 INFO  DAGScheduler:54 - Got job 25 (count at ReferenceData.scala:42) with 1 output partitions
2019-10-02 18:51:57 INFO  DAGScheduler:54 - Final stage: ResultStage 38 (count at ReferenceData.scala:42)
2019-10-02 18:51:57 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 37)
2019-10-02 18:51:57 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 37)
2019-10-02 18:51:57 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 37 (MapPartitionsRDD[139] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:57 INFO  MemoryStore:54 - Block broadcast_63 stored as values in memory (estimated size 14.4 KB, free 1963.5 MB)
2019-10-02 18:51:57 INFO  MemoryStore:54 - Block broadcast_63_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1963.5 MB)
2019-10-02 18:51:57 INFO  BlockManagerInfo:54 - Added broadcast_63_piece0 in memory on user-PC:62456 (size: 8.1 KB, free: 1965.1 MB)
2019-10-02 18:51:57 INFO  SparkContext:54 - Created broadcast 63 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:57 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[139] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:57 INFO  TaskSchedulerImpl:54 - Adding task set 37.0 with 1 tasks
2019-10-02 18:51:57 INFO  TaskSetManager:54 - Starting task 0.0 in stage 37.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 8369 bytes)
2019-10-02 18:51:57 INFO  Executor:54 - Running task 0.0 in stage 37.0 (TID 37)
2019-10-02 18:51:57 INFO  FileScanRDD:54 - Reading File path: file:///D:/Contracting/201909%20-%20CWT%20Job%20Interview%20and%20Process/ReferenceData/Weather_Conditions_Code.csv, range: 0-221, partition values: [empty row]
2019-10-02 18:51:57 INFO  Executor:54 - Finished task 0.0 in stage 37.0 (TID 37). 1540 bytes result sent to driver
2019-10-02 18:51:57 INFO  TaskSetManager:54 - Finished task 0.0 in stage 37.0 (TID 37) in 25 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:57 INFO  TaskSchedulerImpl:54 - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2019-10-02 18:51:57 INFO  DAGScheduler:54 - ShuffleMapStage 37 (count at ReferenceData.scala:42) finished in 0.031 s
2019-10-02 18:51:57 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-10-02 18:51:57 INFO  DAGScheduler:54 - running: Set()
2019-10-02 18:51:57 INFO  DAGScheduler:54 - waiting: Set(ResultStage 38)
2019-10-02 18:51:57 INFO  DAGScheduler:54 - failed: Set()
2019-10-02 18:51:57 INFO  DAGScheduler:54 - Submitting ResultStage 38 (MapPartitionsRDD[142] at count at ReferenceData.scala:42), which has no missing parents
2019-10-02 18:51:57 INFO  MemoryStore:54 - Block broadcast_64 stored as values in memory (estimated size 7.3 KB, free 1963.5 MB)
2019-10-02 18:51:57 INFO  MemoryStore:54 - Block broadcast_64_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1963.5 MB)
2019-10-02 18:51:57 INFO  BlockManagerInfo:54 - Added broadcast_64_piece0 in memory on user-PC:62456 (size: 3.8 KB, free: 1965.1 MB)
2019-10-02 18:51:57 INFO  SparkContext:54 - Created broadcast 64 from broadcast at DAGScheduler.scala:1039
2019-10-02 18:51:57 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[142] at count at ReferenceData.scala:42) (first 15 tasks are for partitions Vector(0))
2019-10-02 18:51:57 INFO  TaskSchedulerImpl:54 - Adding task set 38.0 with 1 tasks
2019-10-02 18:51:57 INFO  TaskSetManager:54 - Starting task 0.0 in stage 38.0 (TID 38, localhost, executor driver, partition 0, ANY, 7754 bytes)
2019-10-02 18:51:57 INFO  Executor:54 - Running task 0.0 in stage 38.0 (TID 38)
2019-10-02 18:51:57 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2019-10-02 18:51:57 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2019-10-02 18:51:57 INFO  Executor:54 - Finished task 0.0 in stage 38.0 (TID 38). 1739 bytes result sent to driver
2019-10-02 18:51:57 INFO  TaskSetManager:54 - Finished task 0.0 in stage 38.0 (TID 38) in 5 ms on localhost (executor driver) (1/1)
2019-10-02 18:51:57 INFO  TaskSchedulerImpl:54 - Removed TaskSet 38.0, whose tasks have all completed, from pool 
2019-10-02 18:51:57 INFO  DAGScheduler:54 - ResultStage 38 (count at ReferenceData.scala:42) finished in 0.009 s
2019-10-02 18:51:57 INFO  DAGScheduler:54 - Job 25 finished: count at ReferenceData.scala:42, took 0.042887 s
---------------------------------------------------------------------------------------------------------
The Reference Table :Weather_Conditions_Code : Loaded into HIVE with counts of 10
---------------------------------------------------------------------------------------------------------
2019-10-02 18:51:57 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-10-02 18:51:57 INFO  AbstractConnector:318 - Stopped Spark@12c7a01b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-02 18:51:57 INFO  SparkUI:54 - Stopped Spark web UI at http://user-PC:4040
2019-10-02 18:51:57 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-10-02 18:51:58 INFO  MemoryStore:54 - MemoryStore cleared
2019-10-02 18:51:58 INFO  BlockManager:54 - BlockManager stopped
2019-10-02 18:51:58 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-10-02 18:51:58 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-10-02 18:51:58 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-10-02 18:51:58 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-10-02 18:51:58 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-04c3fcf7-e204-4898-ab80-ef9226d7a151
